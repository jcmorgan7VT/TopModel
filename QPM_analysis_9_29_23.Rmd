---
title: "QPM_analysis_9_29_23"
author: "John Morgan"
date: "2023-09-29"
output: html_document
editor_options: 
  chunk_output_type: console
---
After meeting with Kevin and JP, I am doing an analysis that will be more useful for everyone else at Hubbard Brook. Things I need to do:
- Define a normal channel for each watershed
  - Start with W3, use known extent to develop an area threshold, then use that on other watersheds
- Determine how frequently streams connect with biogeochemical hotspots (rocky areas, shallow soils)
  - Use BOSS to get rocky areas and shallow soils
  - How often does the channel expand up into these areas?
  - What stream expansion threshold connects with hotspots?
- How much does stream area change during the growing season?
  - Map of stream channel, color scale by log(days flowing)
  - What area of stream is flowing over time? How does this translate to biogeochemical fluxes (CO2) from the flowing surface of water?
    - Find CO2 fluxes in NE headwater streams
- The streams are dynamic in the middle ranges- how do I express this? (Less important than others)

```{r}
#setup chunk
library(pacman)
p_load(tidyverse, raster, rgdal, sp, sf, mapview,
       rgeos, spdplyr, tmap, stars,
       lubridate, gganimate, animation, patchwork,
       whitebox, grid, scales, ggthemes, viridis,
       parallel, future.apply) 
```


```{r}
#defining a normal channel
#threshold drainage area, based on shapefiles of channel locations that Scott provided
#uaa calculated in script QPM_analysis_9_9_23.Rmd
flowacc_path <- "./HB/5m hydro enforced DEM/TWI_andotherlayers/flowacc.tif"
flowacc <- raster(flowacc_path)
crs(flowacc) <- 26919
crs(flowacc)

#watershed 3 shape
sheds <- readOGR(dsn='./HB/hbef_wsheds')
w3 <- sheds %>% filter(WS == "WS3")

#reading in streams as rasters datasets, created in arcgis
w3_rast <- raster("./HB/hbstream/w3_5m.tif")
fb_rast <- raster("./HB/hbstream/fb_5m.tif")
zz_rast <- raster("./HB/hbstream/zz_5m.tif")
#use this layer, flow accumulation of 3500 m2 from 1m DEM of the whole valley
whole <- raster("./HB/hbstream/wholeValley1m_3500m2Thresh.tif")

stream <- st_read("./HB/hbstream/hb42_master_startend.shp")
fb <- st_read("./HB/hbstream/FB_subcatchment_flowlines.shp")
zz <- st_read("./HB/hbstream/ZZ_subcatchment_flowlines.shp")
#st_crs(stream)

st_crs(stream) <- 26919
st_crs(fb) <- 26919
st_crs(zz) <- 26919


#past method of making the crs of stream match that of a raster
#now should use the method above
#stream_p <- spTransform(stream, crs(flowacc))
#st_crs(stream_p)


plot(flowacc)

#could sub in a more sophisticated method later
```
  
```{r}
#clip to extent of watershed 3
flo_crop <- crop(flowacc, w3)
flo_mask <- mask(flo_crop, w3)
test3 <- flo_mask
test3$flowacc[test3$flowacc < 1000] <- 0
test3$flowacc[test3$flowacc >= 1000] <- 1

binary <- c("#001219",
            "#94D2BD"
  )
test <- as.data.frame(test3, xy = TRUE) %>%
  na.omit()
ggplot() +  
  geom_raster(data=test, aes(x=x, y=y, fill=as.factor(flowacc)))+
  scale_fill_manual(values = binary,
                    labels = c("No flow", "flowing"),
                    name = "")+
    theme_void()+
    theme(legend.position = "bottom")+
  coord_equal()
```

Figuring out how to determine if stream within a predefined channel is flowing:
```{r}
#before function, create inputs
#clipped flow accumulation raster
w3 <- sheds %>% filter(WS == "WS3")


flo_crop <- crop(flowacc, w3)
flo_mask <- mask(flo_crop, w3)


#threshold flow accumulation raster
flo_mask$flowacc[flo_mask$flowacc < 700] <- NA
flo_mask$flowacc[flo_mask$flowacc >= 700] <- 1
#using a critical drainage area of 700 * 5 m^2, or 3500 m^2 by     default

#function to calculate probability of flow raster
willit <- function(input_logtwi, inputQ){
  #b0, or intercept from Kevin's email from Carrie, might need to redo regression
  b0 <- -35.43
  #all ofther coefs from Jensen et al. 2018
  twi_coef <- 15.57
  flow_coef <- 0.12

  b1x1 <- flow_coef * inputQ
  b2x2 <- twi_coef * input_logtwi

  #logistic regression from Jensen et al. 2018
  p <- exp(b0 + b1x1 + b2x2)/(1 + exp(b0 + b1x1 + b2x2))
  return(p)
}

#twi for w3
twi_output <- "./HB/5m hydro enforced DEM/TWI_andotherlayers/twi.tif"
twi <- raster(twi_output)

twi_crop <- crop(twi, w3)
w3_twi <- mask(twi_crop, w3)

#function that takes discharge as single input
q_data <- read.csv("./HB/HBEF_DailyStreamflow_1956-2022.csv")
q_data$DATE <- ymd(q_data$DATE)
w3_q <- filter(q_data, WS == 3)


qlist <- w3_q %>% 
  dplyr::select(DATE, Streamflow)

probable_flow_extent <- function(qlist){
  out <- willit(log(w3_twi), qlist$Streamflow)
  crs(out) <- 26919

  out[out < 0.9] <- 0
  out[out >= 0.9] <- 1
  
  #removes values that are not within pre-defined channel
  masked <- mask(out, flo_mask)

  g_df <- masked %>%
    rasterToPoints %>%
    as.data.frame() %>% 
    mutate(Date = qlist$DATE)

  return(g_df)
}

output <- probable_flow_extent(qlist[6,])
write.csv(results, "./twi_model_rasters/days_flowing/test.csv")

head(output)
ggplot(output)+
    geom_tile(aes(x = x, y = y, fill = layer))+
    theme_void()+
    coord_equal()

```

Use parallel processing and the procedure developed in the previous chunk to determine 
```{r}
#dont run
#modifying parallel part of script from QPM_analsis_9_9_23 to create a raster or df with the number of days flowing through the entire record

#function that will calculate prob, then produce how much was likely flowing
#rasList <- paste0("./twi_model_rasters/w3_", dates, ".tif")
qlist <- w3_q$Streamflow
probable_flow_extent <- function(qlist){
  out <- willit(log(w3_twi), qlist)
  
  out[out < 0.9] <- 0
  out[out >= 0.9] <- 1


  g_df <- out %>%
    rasterToPoints %>%
    as.data.frame()

  flowing_area <- sum(g_df$layer)
  return(flowing_area)
}

probable_flow_extent(qlist[6])

plan(multicore, workers = detectCores() - 1)
outStat <- future_lapply(qlist, probable_flow_extent)

results <- data.frame("Q" = w3_q$Streamflow, 
                      "Date" = w3_q$DATE,
                      "Cells_flowing" = unlist(outStat))
write.csv(results, "./twi_model_rasters/w3_flowing_days.csv")
```

Trying JP method: convert raster of channel to points, then find log(twi) at each point, determine threshold to flow, then I am in dataframe land
```{r}
#pull in raster that defines pre-existing channel
w3 <- sheds %>% filter(WS == "WS3")
flo_crop <- crop(flowacc, w3)
flo_mask <- mask(flo_crop, w3)
#threshold flow accumulation raster
flo_mask$flowacc[flo_mask$flowacc < 700] <- NA
flo_mask$flowacc[flo_mask$flowacc >= 700] <- 1
#using a critical drainage area of 700 * 5 m^2, or 3500 m^2 by     default

#convert channel raster into a df
#OR convert twi raster to df once it has been masked by 
twi <- raster("./HB/5m hydro enforced DEM/TWI_andotherlayers/twi.tif")

twi_crop <- crop(twi, w3)
w3_twi <- mask(twi_crop, w3)

masked <- mask(log(w3_twi), flo_mask)

#convert raster to points
mask_logtwi <- masked %>%
    rasterToPoints %>%
    as.data.frame() 

  
#calculating probability that the cell is flowing  
mask_logtwi$prob <- willit(mask_logtwi$layer, 10)
ggplot(mask_logtwi)+
    geom_tile(aes(x = x, y = y, fill = prob))+
    theme_void()+
    coord_equal()

mask_logtwi$binary <- 0
mask_logtwi$binary[mask_logtwi$prob < 0.9] <- 0
mask_logtwi$binary[mask_logtwi$prob >= 0.9] <- 1

length(mask_logtwi$layer)
length(unique(mask_logtwi$layer))

#write the inverse/logit function
logit <- function(p) {
  log(p / (1 - p))
}


#function where I input twi and probability, and it gives me the discharge!
logit <- function(prob, input_logtwi) {
  inverse <- log(prob / (1 - prob))
#b0, or intercept from Kevin's email from Carrie, might need to redo regression
  b0 <- -35.43
  #all ofther coefs from Jensen et al. 2018
  twi_coef <- 15.57
  b1 <- 0.12

    b2x2 <- twi_coef * input_logtwi
  
  x1 <- (inverse - b2x2 - b0) / b1
  
return(x1)

}

#testing logit function
mask_logtwi$logit <- logit(mask_logtwi$prob, mask_logtwi$layer)


head(mask_logtwi[mask_logtwi$binary == 1,])
head(mask_logtwi)

#now apply logit function to each cell in channel with 0.9 prob
mask_logtwi2 <- masked %>%
    rasterToPoints %>%
    as.data.frame()

#this column in the dataframe is the discharge required for that cell to flow
mask_logtwi2$Q_required <- logit(0.9, mask_logtwi2$layer)
head(mask_logtwi2)
head(mask_logtwi2[mask_logtwi2$Q_req <= 10,])
mask_logtwi2[mask_logtwi2$Q_req == min(mask_logtwi2$Q_req),]


#now, count how many times that discharge is reached for each cell, then convert to percent

#read in discharge
#growing_szn is discharge filtered to just the growing season
growing_szn <- read_csv("growing_szn.csv")
growing_szn <- growing_szn[,3:7]

#q_data <- read.csv("./HB/HBEF_DailyStreamflow_1956-2022.csv")
#q_data$DATE <- ymd(q_data$DATE)
w3_q <- filter(growing_szn, WS == 3)
qlist <- w3_q %>% 
  dplyr::select(Date, Q)
qlist$year <- year(qlist$Date)

howManyQ <- function(Q_req){
  length(qlist$Q[qlist$Q >= Q_req])
}

mask_logtwi2$count <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ))
mask_logtwi2$percent_time_flowing <- mask_logtwi2$count / length(qlist$Date)
head(mask_logtwi2)

#I don't need to turn it back into a raster, keep it as a df for plotting purposes
ggplot(mask_logtwi2)+
    geom_tile(aes(x = x, y = y, fill = percent_time_flowing * 100))+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(100, 10, 1),
                     labels = c("100", "10", "1"))+
  coord_equal()+
  labs(fill='Percent of time flowing (days)')
#make this plot for each watershed

#see if it is changing through time
#group them by decade
qlist <- qlist %>% mutate(decade = floor(year/10)*10)
howManyQ2 <- function(Q_req){
  length(qlist2$Q[qlist2$Q >= Q_req])
}
#for each decade, calculate percentage of time flowing
qlist2 <- filter(qlist, decade == 1950)
mask_logtwi2$y1950 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 1960)
mask_logtwi2$y1960 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 1970)
mask_logtwi2$y1970 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 1980)
mask_logtwi2$y1980 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 1990)
mask_logtwi2$y1990 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 2000)
mask_logtwi2$y2000 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 2010)
mask_logtwi2$y2010 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 2020)
mask_logtwi2$y2020 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
head(mask_logtwi2)

mapping <- dplyr::select(mask_logtwi2, -Q_required, -count) %>% 
  gather(key = "year", value = "value", c(-x, -y, -layer))

#plot of all of the decades to compare
ggplot(mapping)+
    geom_tile(aes(x = x, y = y, fill = value * 100))+
  facet_wrap(~year)+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(100, 10, 1),
                     labels = c("100", "10", "1"))+
  coord_equal()+
  labs(fill='Percent of time flowing (days)')

#make plot of all of the decades subtracted from the all time record
mapping <- dplyr::select(mask_logtwi2, -Q_required, -count) %>% 
  gather(key = "year", value = "value", c(-x, -y, -layer))

#remove the least interesting decades
mapping <- dplyr::select(mask_logtwi2, -Q_required, -count, -y1960, -y2000, -y2010, 
                         -y1990) %>% 
  gather(key = "year", value = "value", c(-x, -y, -layer))

diffs <- mapping %>% 
  group_by(year) %>% 
  mutate(difference = mask_logtwi2$percent_time_flowing - value) %>% 
  filter(year != "percent_time_flowing")
  #removing all but most interesting years

diffs$year <- sub('.', '', diffs$year)

ggplot(diffs)+
    geom_tile(aes(x = x, y = y, fill = difference * 100))+
  facet_grid(~year)+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(10, 1, 0.1),
                     labels = c("10", "1", "0.1"),
                     option = "plasma")+
  coord_equal()+
  labs(fill='% More time of flow from average')+
  theme(legend.position = "bottom",
        text=element_text(size=21))

```


Attempt to quantify how CO2 evasion is changing based on changing surface area
```{r}
#4.0 g C/m2-yr of CO2 evaded from streams, from
# Fahey, T.J., Siccama, T.G., Driscoll, C.T. et al. The Biogeochemistry of Carbon at Hubbard Brook. Biogeochemistry 75, 109–176 (2005). https://doi-org.ezproxy.lib.vt.edu/10.1007/s10533-004-6321-y

#I already have how many cells are flowing at each time step for each watershed,
#just need to calculate a surface area and emissions based on surface area through time
ws3 <- growing_szn %>% 
  filter(WS == 3) %>% 
  mutate(CO2 = Cells_flowing * 20/365)

ws3[,"cum_CO2"] <- cumsum(ws3$CO2)

ggplot(ws3)+
  geom_point(aes(x = Q, y = CO2))+
  theme_classic()

ws3[which.max(ws3$Cells_flowing),]

ws3 <- ws3[-(which(ws3$Date == "1973-06-30")),]


ws3_yearsums <- ws3 %>% 
  group_by(year(Date)) %>% 
  mutate(yearly_sum = sum(CO2)) %>% 
  as.data.frame()



#should remove June 30, 1973 from dataset- it is a freakish outlier and breaks the model
#(ws3_yearsums[ws3_yearsums$Cells_flowing == max(ws3_yearsums$Cells_flowing),])
ws3_yearsums[which.max(ws3_yearsums$Cells_flowing),]

#also exclude first and last years
ws3_yearsums <- ws3_yearsums[-1,]
ws3_yearsums <- ws3_yearsums[-(which(ws3_yearsums[,8] == 2022)),]
ws3_yearsums$year <- year(ws3_yearsums$Date)
#plot of yearly CO2 evasion for W3


#adding sens slope
p_load(mblm, Kendall)
sen <- function(formula, dataframe, weights = NULL) {
  mblm::mblm(formula, dataframe)
}
#problem was having duplicate years
blest <- ws3_yearsums %>% 
  dplyr::select(year, yearly_sum) %>% 
  unique()
#sen(test, as.numeric(cells_flowing_byArea), final_df)
MannKendall(blest$yearly_sum)

fit <- mblm(year ~ yearly_sum, dataframe = blest)
fit2 <- sen(n ~ year, tr)

ggplot(blest,
       aes(x = year, y = yearly_sum)) +
  geom_line() +
  geom_point(size = 2) +
  theme_classic() +
  geom_smooth(method = sen, se = FALSE)+#, aes(color = "blue")) +
  #scale_colour_manual(name=" ", values=c("blue"),labels = "Sen's Slope")+

  labs(title = expression("Yearly CO"["2"]~" evasion, W3"),
       subtitle = "p = 0.0053",
       x = "Year",
       y = expression(CO[2] ~ " (g)"))

#Successfully made CO2 estimate for W3, now do it for the other ones
```

Making CO2 evasion estimates and graphs for watersheds 3, 6, 7, 8
```{r}
#doing the same thing as above, but using all four and group by
ws3 <- growing_szn %>% 
  filter(WS %in% c(3, 6, 7, 8)) %>% 
  group_by(WS) %>% 
  mutate(CO2 = Cells_flowing * 20/365)
#removing freak event on jun 30, 1973
ws3 <- ws3[-(which(ws3$Date == "1973-06-30")),]

ws3$year <- year(ws3$Date)

ws3_yearsums <- ws3 %>% 
  group_by(WS, year) %>% 
  mutate(yearly_sum = sum(CO2))



#should remove June 30, 1973 from dataset- it is a freakish outlier and breaks the model
#(ws3_yearsums[ws3_yearsums$Cells_flowing == max(ws3_yearsums$Cells_flowing),])
ws3_yearsums[which.max(ws3_yearsums$Cells_flowing),]

#also exclude first and last years
ws3_yearsums <- ws3_yearsums[-(which(ws3$Date == "1957-10-01")),]
ws3_yearsums <- ws3_yearsums[-(which(ws3_yearsums$year == 2022)),]
#plot of yearly CO2 evasion for W3


#adding sens slope
p_load(mblm, Kendall)
sen <- function(formula, dataframe, weights = NULL) {
  mblm::mblm(formula, dataframe)
}
#problem was having duplicate years
blest <- ws3_yearsums %>% 
  dplyr::select(WS, year, yearly_sum) %>% 
  unique()

ggplot(blest,
       aes(x = year, y = yearly_sum)) +
  geom_line() +
  geom_point(size = 2) +
  theme_classic() +
  facet_wrap(~WS, scales = "free_y")+
  geom_smooth(method = sen, se = FALSE)+#, aes(color = "blue")) +
  #scale_colour_manual(name=" ", values=c("blue"),labels = "Sen's Slope")+

  labs(title = expression("Yearly CO"["2"]~" evasion, W3"),
       subtitle = "p = ",
       x = "Year",
       y = expression(CO[2] ~ " (g)"))

```


```{r}
#find where expanded channels reach into rocky outcrops and shallow soil


#read in soil model
soil_map_path <- "./HB/HBsoils.tif"
#twi calculated in script topmodel_fromscratch_2_23_23.Rmd
soil <- raster(soil_map_path)
crs(soil) <- 26919



```

```{r}
growing_szn <- read_csv("growing_szn.csv")
growing_szn <- growing_szn[,3:7]



test <- willit(log(twi3), 30)
plot(test)
test[test < 0.9] <- NA
test[test >= 0.9] <- 1

plot(test)
r.new = resample(w3_rast, test, "bilinear")


diff <- w3_rast + test
plot(r.new)

```
  
```{r}
#just do watersheds 3, 6, 7, 8
twi_output <- "./HB/5m hydro enforced DEM/TWI_andotherlayers/twi.tif"
twi <- raster(twi_output)

w3 <- sheds %>% filter(WS == "WS3")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w3)
w3_net <- mask(whole_crop, w3)
twi_crop <- crop(twi, w3)
w3_twi <- mask(twi_crop, w3)

w6 <- sheds %>% filter(WS == "WS6")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w6)
w6_net <- mask(whole_crop, w6)
twi_crop <- crop(twi, w6)
w6_twi <- mask(twi_crop, w6)

w7 <- sheds %>% filter(WS == "WS7")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w7)
w7_net <- mask(whole_crop, w7)
twi_crop <- crop(twi, w7)
w7_twi <- mask(twi_crop, w7)

w8 <- sheds %>% filter(WS == "WS8")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w8)
w8_net <- mask(whole_crop, w8)
twi_crop <- crop(twi, w8)
w8_twi <- mask(twi_crop, w8)


#symbology for soils
labels <- c("Bh Podzol",
            "Bhs Podzol",
            "Bimodal Podzol",
            "E Podzol",
            "Wetland Histosol",
            "Aquept",
             "Bedrock Histosol",
            "Typical Podzol"
            )

colors <- c("#55FF00",
            "#734C00",
            "#267300",
            "#CCCCCC",
            "#004DA8",
            "#00C5FF",
            "black",
            "#FFFF73"
            )


breaks <- c(1,2,3,4,5,6,7,8)
tmap_mode("view")
tm_shape(soil, raster.downsample = FALSE)+
  tm_raster(style = "cat", #fixed problem by specifying style
            palette = colors, labels = labels, breaks = breaks)
```

```{r}
w3 <- sheds %>% filter(WS == "WS8")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w3)
w3_net <- mask(whole_crop, w3)
twi_crop <- crop(twi, w3)
w3_twi <- mask(twi_crop, w3)
plot(w3_net)
test <- willit(log(w3_twi), 30)
test[test < 0.9] <- NA
test[test >= 0.9] <- 1
r.new = resample(w3_net, test, "bilinear")

x <- mask(B, A)




  tm_shape(soil)+
  tm_raster(palette = colors, labels = labels, breaks = breaks)+
    tm_shape(test)+

  tm_raster(palette = "red")
#w3- anything above 40
#ws6- anything above 45
#ws7- anything above 50
#ws8- anything above 30
```

Number of times streams lick rocks per year
```{r}
data3 <- growing_szn %>% filter(WS == 3) %>% 
  filter(Q >= 40)
data6 <- growing_szn %>% filter(WS == 6) %>% 
  filter(Q >= 45)
data7 <- growing_szn %>% filter(WS == 7) %>% 
  filter(Q >= 50)
data8 <- growing_szn %>% filter(WS == 8) %>% 
  filter(Q >= 30)

data_all <- rbind(data3, data6)
data_all <- rbind(data_all, data7)
data_all <- rbind(data_all, data8) %>% 
  mutate(year = year(Date)) %>% 
  group_by(year, WS)%>%
    summarise(Count = n())

ggplot(data_all)+
  geom_col(aes(x = year, y = Count), fill = "black")+
  facet_wrap(~WS, )+
  labs(title = "Number of times streams lick rocks per year")+
  theme_classic()



```
10/13/23, just had meeting with JP and kevin
- make figure showing percentage of time flowing or log duration of flow in hours for each stream based on model, do for each growing season and see if there are noticeable changes through time
-     Channels might have changed over this time scale
- Develop a more sophisticated way to determine when the channel intersects with shallow rocky soil

```{r}

```

