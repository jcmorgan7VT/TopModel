---
title: "QPM_analysis_9_29_23"
author: "John Morgan"
date: "2023-09-29"
output: html_document
editor_options: 
  chunk_output_type: console
---
After meeting with Kevin and JP, I am doing an analysis that will be more useful for everyone else at Hubbard Brook. Things I need to do:
- Define a normal channel for each watershed
  - Start with W3, use known extent to develop an area threshold, then use that on other watersheds
- Determine how frequently streams connect with biogeochemical hotspots (rocky areas, shallow soils)
  - Use BOSS to get rocky areas and shallow soils
  - How often does the channel expand up into these areas?
  - What stream expansion threshold connects with hotspots?
- How much does stream area change during the growing season?
  - Map of stream channel, color scale by log(days flowing)
  - What area of stream is flowing over time? How does this translate to biogeochemical fluxes (CO2) from the flowing surface of water?
    - Find CO2 fluxes in NE headwater streams
- The streams are dynamic in the middle ranges- how do I express this? (Less important than others)

2/23/24
Adapting script from rgeos and raster land to do analysis that Linda is thinking about. (Never finished)

3/18/24
Adapting script to test against my observations of flow

6/30/25
Need to convert this to terra land, currently still using raster package. Doing follow up analysis for Danielle's control point paper.

```{r}
#setup chunk
library(pacman)
p_load(tidyverse, terra, rgdal, sp, sf, mapview, spdplyr, tmap, stars,
       lubridate, gganimate, animation, patchwork,
       whitebox, grid, scales, ggthemes, viridis,
       parallel, future.apply) 
```


```{r prepare-network-shapes}
#defining a normal channel
#threshold drainage area, based on shapefiles of channel locations that Scott provided
#uaa calculated in script QPM_analysis_9_9_23.Rmd
flowacc_path <- "./HB/5m hydro enforced DEM/TWI_andotherlayers/flowacc.tif"
flowacc <- raster(flowacc_path)
crs(flowacc) <- 26919
crs(flowacc)

#watershed 3 shape
sheds <- readOGR(dsn='./HB/hbef_wsheds')
w3 <- sheds %>% filter(WS == "WS3")

#reading in streams as rasters datasets, created in arcgis
w3_rast <- raster("./HB/hbstream/w3_5m.tif")
fb_rast <- raster("./HB/hbstream/fb_5m.tif")
zz_rast <- raster("./HB/hbstream/zz_5m.tif")
#use this layer, flow accumulation of 3500 m2 from 1m DEM of the whole valley
whole <- raster("./HB/hbstream/wholeValley1m_3500m2Thresh.tif")

stream <- st_read("./HB/hbstream/hb42_master_startend.shp")
fb <- st_read("./HB/hbstream/FB_subcatchment_flowlines.shp")
zz <- st_read("./HB/hbstream/ZZ_subcatchment_flowlines.shp")
#st_crs(stream)

st_crs(stream) <- 26919
st_crs(fb) <- 26919
st_crs(zz) <- 26919


#past method of making the crs of stream match that of a raster
#now should use the method above
#stream_p <- spTransform(stream, crs(flowacc))
#st_crs(stream_p)


#could sub in a more sophisticated method later
```
  
```{r plot-W3}
#clip to extent of watershed 3
flo_crop <- crop(flowacc, w3)
flo_mask <- mask(flo_crop, w3)
test3 <- flo_mask
test3$flowacc[test3$flowacc < 700] <- 0
test3$flowacc[test3$flowacc >= 700] <- 1

binary <- c("#001219",
            "#94D2BD"
  )
test <- as.data.frame(test3, xy = TRUE) %>%
  na.omit()
ggplot() +  
  geom_raster(data=test, aes(x=x, y=y, fill=as.factor(flowacc)))+
  scale_fill_manual(values = binary,
                    labels = c("No flow", "flowing"),
                    name = "")+
    theme_void()+
    theme(legend.position = "bottom")+
  coord_equal()
```

Figuring out how to determine if stream within a predefined channel is flowing:
```{r figuring-out-model}
#before function, create inputs
#clipped flow accumulation raster
w3 <- sheds %>% filter(WS == "WS3")


flo_crop <- crop(flowacc, w3)
flo_mask <- mask(flo_crop, w3)


#threshold flow accumulation raster
flo_mask$flowacc[flo_mask$flowacc < 700] <- NA
flo_mask$flowacc[flo_mask$flowacc >= 700] <- 1
#using a critical drainage area of 700 * 5 m^2, or 3500 m^2 by     default

#function to calculate probability of flow raster
willit <- function(input_logtwi, inputQ){
  #b0, or intercept from Kevin's email from Carrie, might need to redo regression
  b0 <- -35.43
  #all ofther coefs from Jensen et al. 2018
  twi_coef <- 15.57
  flow_coef <- 0.12

  b1x1 <- flow_coef * inputQ
  b2x2 <- twi_coef * input_logtwi

  #logistic regression from Jensen et al. 2018
  p <- exp(b0 + b1x1 + b2x2)/(1 + exp(b0 + b1x1 + b2x2))
  return(p)
}

#twi for w3
twi_output <- "./HB/5m hydro enforced DEM/TWI_andotherlayers/twi.tif"
twi <- raster(twi_output)

twi_crop <- crop(twi, w3)
w3_twi <- mask(twi_crop, w3)

#function that takes discharge as single input
q_data <- read.csv("./HB/HBEF_DailyStreamflow_1956-2022.csv")
q_data$DATE <- ymd(q_data$DATE)
w3_q <- filter(q_data, WS == 3)


qlist <- w3_q %>% 
  dplyr::select(DATE, Streamflow)

probable_flow_extent <- function(qlist){
  out <- willit(log(w3_twi), qlist$Streamflow)
  crs(out) <- 26919

  out[out < 0.9] <- 0
  out[out >= 0.9] <- 1
  
  #removes values that are not within pre-defined channel
  masked <- mask(out, flo_mask)

  g_df <- masked %>%
    rasterToPoints %>%
    as.data.frame() %>% 
    mutate(Date = qlist$DATE)

  return(g_df)
}

output <- probable_flow_extent(qlist[21824 ,])
output <- probable_flow_extent(qlist[23656  ,])

#write.csv(results, "./twi_model_rasters/days_flowing/test.csv")
qlist[(which(qlist$Streamflow >= 30)),]

binary <- c("#001011",
            "#6ccff6"
  )

head(output)
ggplot(output)+
    geom_tile(aes(x = x, y = y, fill = as.factor(layer)))+
  scale_fill_manual(values = binary,
                    labels = c("Not Flowing", "Flowing"),
                    name = "")+
    theme_void()+
    coord_equal()+
  labs(title = unique(output$Date))

```


JP Method works!: convert raster of channel to points, then find log(twi) at each point, determine threshold to flow, then I am in dataframe land
```{r run-model-all-decades}
#pull in raster that defines pre-existing channel
w3 <- sheds %>% filter(WS == "WS3")
flo_crop <- crop(flowacc, w3)
flo_mask <- mask(flo_crop, w3)
#threshold flow accumulation raster
flo_mask$flowacc[flo_mask$flowacc < 700] <- NA
flo_mask$flowacc[flo_mask$flowacc >= 700] <- 1
#using a critical drainage area of 700 * 5 m^2, or 3500 m^2 by     default

#convert channel raster into a df
#OR convert twi raster to df once it has been masked by 
twi <- raster("./HB/5m hydro enforced DEM/TWI_andotherlayers/twi.tif")

twi_crop <- crop(twi, w3)
w3_twi <- mask(twi_crop, w3)

masked <- mask(log(w3_twi), flo_mask)

#convert raster to points
mask_logtwi <- masked %>%
    rasterToPoints %>%
    as.data.frame() 

  
#calculating probability that the cell is flowing  
mask_logtwi$prob <- willit(mask_logtwi$layer, 10)
ggplot(mask_logtwi)+
    geom_tile(aes(x = x, y = y, fill = prob))+
    theme_void()+
    coord_equal()

mask_logtwi$binary <- 0
mask_logtwi$binary[mask_logtwi$prob < 0.9] <- 0
mask_logtwi$binary[mask_logtwi$prob >= 0.9] <- 1

length(mask_logtwi$layer)
length(unique(mask_logtwi$layer))

#write the inverse/logit function
logit <- function(p) {
  log(p / (1 - p))
}


#function where I input twi and probability, and it gives me the discharge!
logit <- function(prob, input_logtwi) {
  inverse <- log(prob / (1 - prob))
#b0, or intercept from Kevin's email from Carrie, might need to redo regression
  b0 <- -35.43
  #all ofther coefs from Jensen et al. 2018
  twi_coef <- 15.57
  b1 <- 0.12

    b2x2 <- twi_coef * input_logtwi
  
  x1 <- (inverse - b2x2 - b0) / b1
  
return(x1)

}

#testing logit function
mask_logtwi$logit <- logit(mask_logtwi$prob, mask_logtwi$layer)


head(mask_logtwi[mask_logtwi$binary == 1,])
head(mask_logtwi)

#now apply logit function to each cell in channel with 0.9 prob
mask_logtwi2 <- masked %>%
    rasterToPoints %>%
    as.data.frame()

#this column in the dataframe is the discharge required for that cell to flow
mask_logtwi2$Q_required <- logit(0.9, mask_logtwi2$layer)
head(mask_logtwi2)
head(mask_logtwi2[mask_logtwi2$Q_req <= 10,])
mask_logtwi2[mask_logtwi2$Q_req == min(mask_logtwi2$Q_req),]


#now, count how many times that discharge is reached for each cell, then convert to percent

#read in discharge
#growing_szn is discharge filtered to just the growing season
growing_szn <- read_csv("growing_szn.csv")
growing_szn <- growing_szn[,3:7]

#q_data <- read.csv("./HB/HBEF_DailyStreamflow_1956-2022.csv")
#q_data$DATE <- ymd(q_data$DATE)
w3_q <- filter(growing_szn, WS == 3)
qlist <- w3_q %>% 
  dplyr::select(Date, Q)
qlist$year <- year(qlist$Date)

howManyQ <- function(Q_req){
  length(qlist$Q[qlist$Q >= Q_req])
}

mask_logtwi2$count <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ))
mask_logtwi2$percent_time_flowing <- mask_logtwi2$count / length(qlist$Date)
head(mask_logtwi2)

#I don't need to turn it back into a raster, keep it as a df for plotting purposes
ggplot(mask_logtwi2)+
    geom_tile(aes(x = x, y = y, fill = percent_time_flowing * 100))+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(100, 10, 1),
                     labels = c("100", "10", "1"))+
  coord_equal()+
  labs(fill='Percent of time flowing (days)')
#make this plot for each watershed

#see if it is changing through time
#group them by decade
qlist <- qlist %>% mutate(decade = floor(year/10)*10)
howManyQ2 <- function(Q_req){
  length(qlist2$Q[qlist2$Q >= Q_req])
}
#for each decade, calculate percentage of time flowing
qlist2 <- filter(qlist, decade == 1950)
mask_logtwi2$y1950 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 1960)
mask_logtwi2$y1960 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 1970)
mask_logtwi2$y1970 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 1980)
mask_logtwi2$y1980 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 1990)
mask_logtwi2$y1990 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 2000)
mask_logtwi2$y2000 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 2010)
mask_logtwi2$y2010 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
qlist2 <- filter(qlist, decade == 2020)
mask_logtwi2$y2020 <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ2)) / length(qlist2$Date)
head(mask_logtwi2)

mapping <- dplyr::select(mask_logtwi2, -Q_required, -count) %>% 
  gather(key = "year", value = "value", c(-x, -y, -layer))

#plot of all of the decades to compare
ggplot(mapping)+
    geom_tile(aes(x = x, y = y, fill = value * 100))+
  facet_wrap(~year)+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(100, 10, 1),
                     labels = c("100", "10", "1"))+
  coord_equal()+
  labs(fill='Percent of time flowing (days)')

#make plot of all of the decades subtracted from the all time record
mapping <- dplyr::select(mask_logtwi2, -Q_required, -count) %>% 
  gather(key = "year", value = "value", c(-x, -y, -layer))

#remove the least interesting decades
mapping <- dplyr::select(mask_logtwi2, -Q_required, -count, -y1960, -y2000, -y2010, 
                         -y1990) %>% 
  gather(key = "year", value = "value", c(-x, -y, -layer))

diffs <- mapping %>% 
  group_by(year) %>% 
  mutate(difference = mask_logtwi2$percent_time_flowing - value) %>% 
  filter(year != "percent_time_flowing")
  #removing all but most interesting years

diffs$year <- sub('.', '', diffs$year)

#problem with the way it was calculated, trying again
summary((mask_logtwi2$y1970 - mask_logtwi2$percent_time_flowing)*100)

ggplot(diffs)+
    geom_tile(aes(x = x, y = y, fill = difference * 100))+
  facet_grid(~year)+
    theme_void()+
  scale_fill_viridis(#breaks = c(),
                     #labels = c("10", "1", "0.1"),
                     option = "plasma")+
  coord_equal()+
  labs(fill='% More time of flow from average')+
  theme(legend.position = "bottom",
        text=element_text(size=21))

```

Figure of percentage of time flowing for each watershed
```{r percentage-of-time-flowing-all-sheds}
#perhaps write a function where the watershed is the input, and then it filters sheds shapefile and discharge record, produces my desired plot or at least the data for desired plot
#pull in raster that defines pre-existing channel
WS <- 3
time_flowing <- function(WS){
  #WS must be in format "3", "6", etc.
  t <- paste0("WS",WS)
  shed <- sheds %>% filter(WS == t)
  #plot(shed)
  flo_crop <- crop(flowacc, shed)
  flo_mask <- mask(flo_crop, shed)
  #threshold flow accumulation raster
  flo_mask$flowacc[flo_mask$flowacc < 700] <- NA
  flo_mask$flowacc[flo_mask$flowacc >= 700] <- 1
#using a critical drainage area of 700 * 5 m^2, or 3500 m^2 by     default

#convert channel raster into a df
#OR convert twi raster to df once it has been masked by 
twi <- raster("./HB/5m hydro enforced DEM/TWI_andotherlayers/twi.tif")

twi_crop <- crop(twi, shed)
shed_twi <- mask(twi_crop, shed)

masked <- mask(log(shed_twi), flo_mask)

#function where I input twi and probability, and it gives me the discharge!
logit <- function(prob, input_logtwi) {
  inverse <- log(prob / (1 - prob))
#b0, or intercept from Kevin's email from Carrie, might need to redo regression
  b0 <- -35.43
  #all ofther coefs from Jensen et al. 2018
  twi_coef <- 15.57
  b1 <- 0.12

    b2x2 <- twi_coef * input_logtwi
  
  x1 <- (inverse - b2x2 - b0) / b1
  
return(x1)

}


#now apply logit function to each cell in channel with 0.9 prob
mask_logtwi2 <- masked %>%
    rasterToPoints %>%
    as.data.frame()

#this column in the dataframe is the discharge required for that cell to flow
mask_logtwi2$Q_required <- logit(0.9, mask_logtwi2$layer)



#now, count how many times that discharge is reached for each cell, then convert to percent

#read in discharge

w3_q <- filter(growing_szn, WS == WS)
qlist <- w3_q %>% 
  dplyr::select(Date, Q)
qlist$year <- year(qlist$Date)

howManyQ <- function(Q_req){
  length(qlist$Q[qlist$Q >= Q_req])
}

mask_logtwi2$count <- as.numeric(lapply(mask_logtwi2$Q_required, howManyQ))
mask_logtwi2$percent_time_flowing <- mask_logtwi2$count / length(qlist$Date)

  return(mask_logtwi2)
}

ws3_flowing <- time_flowing(3)
ws6_flowing <- time_flowing(6)
ws7_flowing <- time_flowing(7)
ws8_flowing <- time_flowing(8)

#I don't need to turn it back into a raster, keep it as a df for plotting purposes
ggplot(ws3_flowing)+
    geom_tile(aes(x = x, y = y, fill = percent_time_flowing * 100))+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(100, 10, 1),
                     labels = c("100", "10", "1"))+
  coord_equal()+
  labs(fill='Percentage of days flowing')+
  theme(legend.position = "none")
ggplot(ws6_flowing)+
    geom_tile(aes(x = x, y = y, fill = percent_time_flowing * 100))+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(100, 10, 1),
                     labels = c("100", "10", "1"))+
  coord_equal()+
  labs(fill='Percentage of days flowing')

ggplot(ws7_flowing)+
    geom_tile(aes(x = x, y = y, fill = percent_time_flowing * 100))+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(100, 10, 1),
                     labels = c("100", "10", "1"))+
  coord_equal()+
  labs(fill='Percentage of days flowing')+
  theme(legend.position = "none")
ggplot(ws8_flowing)+
    geom_tile(aes(x = x, y = y, fill = percent_time_flowing * 100))+
    theme_void()+
  scale_fill_viridis(trans = "log",
                     breaks = c(100, 10, 1),
                     labels = c("100", "10", "1"))+
  coord_equal()+
  labs(fill='Percentage of days flowing')


```

Make mini watersheds for presentation organization
```{r mini-sheds-visualization}
#0d3b66
#ff6663
#57a773
#8e9dcc
  l <- sheds %>% filter(WS == "WS8")
par(new=TRUE)
plot(sheds, col = c("white","#0d3b66", "white", "white", "white",
                    "#ff6663", "white", "white",
                    "#8e9dcc",
                    "#57a773",
                    "white"))
plot(l, col = "#8e9dcc")  

```

Graph of surface area through time, averaged for each year
Could also make graph of max and min surface area for each year
```{r surface-area-through-time-average-each-year}
growing_szn <- read_csv("growing_szn.csv")
growing_szn <- growing_szn[,3:7]
growing_szn <- growing_szn[-(which(growing_szn$Date == "1973-06-30")),]

ws3 <- growing_szn %>% 
  filter(WS %in% c(3,6,7,8)) %>% 
  group_by(WS) %>% 
  mutate(normalized_m2 = (Cells_flowing * 5),
         year = year(Date))

ws3_yearsums <- ws3 %>% 
  group_by(year, WS) %>% 
  mutate(mean = mean(normalized_m2)) %>% 
  as.data.frame()

ws3_yearsums <- ws3_yearsums[-1,]
ws3_yearsums <- ws3_yearsums[-(which(ws3_yearsums$year == 2022)),]

ggplot(ws3_yearsums)+
  geom_line(aes(x = year, y = mean, color = as.character(WS)))+
  theme_classic()


blest <- ws3_yearsums %>% 
  filter(WS == 3) %>% 
  dplyr::select(year, mean) %>% 
  unique()
MannKendall(blest$mean)

#w3 = 0.005137
#w6 = 0.15972
#w7 = 0.83102
#w8 = 0.73146

ggplot(blest,
       aes(x = year, y = mean)) +
  geom_line() +
  geom_point(size = 2) +
  theme_classic() +
  geom_smooth(method = sen, se = FALSE)+#, aes(color = "blue")) +
  scale_colour_manual(name=" ", values=c("blue"),labels = "Sen's Slope")+

  labs(title = expression("Yearly Mean Surface Area, W3"),
       subtitle = "p = 0.005137",
       x = "Year",
       y = "Surface area (m^2)")

```


Attempt to quantify how CO2 evasion is changing based on changing surface area
```{r calc-surface-area-and-CO2}
#4.0 g C/m2-yr of CO2 evaded from streams, from
# Fahey, T.J., Siccama, T.G., Driscoll, C.T. et al. The Biogeochemistry of Carbon at Hubbard Brook. Biogeochemistry 75, 109â€“176 (2005). https://doi-org.ezproxy.lib.vt.edu/10.1007/s10533-004-6321-y

#I already have how many cells are flowing at each time step for each watershed,
#just need to calculate a surface area and emissions based on surface area through time
ws3 <- growing_szn %>% 
  filter(WS == 3) %>% 
  mutate(CO2 = Cells_flowing * 20/365)

growing_szn <- growing_szn[-(which(growing_szn$Date == "1973-06-30")),]



ws3[,"cum_CO2"] <- cumsum(ws3$CO2)



ws3[which.max(ws3$Cells_flowing),]



ws3_yearsums <- ws3 %>% 
  group_by(year(Date)) %>% 
  mutate(yearly_sum = sum(CO2)) %>% 
  as.data.frame()



#should remove June 30, 1973 from dataset- it is a freakish outlier and breaks the model
#(ws3_yearsums[ws3_yearsums$Cells_flowing == max(ws3_yearsums$Cells_flowing),])
ws3_yearsums[which.max(ws3_yearsums$Cells_flowing),]

#also exclude first and last years
ws3_yearsums <- ws3_yearsums[-1,]
ws3_yearsums <- ws3_yearsums[-(which(ws3_yearsums[,8] == 2022)),]
ws3_yearsums$year <- year(ws3_yearsums$Date)
#plot of yearly CO2 evasion for W3


#adding sens slope
p_load(mblm, Kendall)
sen <- function(formula, dataframe, weights = NULL) {
  mblm::mblm(formula, dataframe)
}
#problem was having duplicate years
blest <- ws3_yearsums %>% 
  dplyr::select(year, yearly_sum) %>% 
  unique()
#sen(test, as.numeric(cells_flowing_byArea), final_df)
MannKendall(blest$yearly_sum)

fit <- mblm(year ~ yearly_sum, dataframe = blest)

ggplot(blest,
       aes(x = year, y = yearly_sum)) +
  geom_line() +
  geom_point(size = 2) +
  theme_classic() +
  #geom_smooth(method = sen, se = FALSE)+#, aes(color = "blue")) +
  #scale_colour_manual(name=" ", values=c("blue"),labels = "Sen's Slope")+

  labs(title = expression("Yearly CO"["2"]~" evasion, W8"),
       subtitle = "p = 0.74272",
       x = "Year",
       y = expression(CO[2] ~ " (g)"))

#Successfully made CO2 estimate for W3, now do it for the other ones
```

Making CO2 evasion estimates and graphs for watersheds 3, 6, 7, 8
```{r}
growing_szn <- read_csv("growing_szn.csv")
growing_szn <- growing_szn[,3:7]
#doing the same thing as above, but using all four and group by
ws3 <- growing_szn %>% 
  filter(WS %in% c(3, 6, 7, 8)) %>% 
  group_by(WS) %>% 
  mutate(CO2 = Cells_flowing * 20/365,
         flowing_area_m2 = Cells_flowing * 5) 
#removing freak event on jun 30, 1973
ws3 <- ws3[-(which(ws3$Date == "1973-06-30")),]

ws3$year <- year(ws3$Date)

ws3_yearsums <- ws3 %>% 
  group_by(WS, year) %>% 
  mutate(yearly_sum = sum(CO2))



#should remove June 30, 1973 from dataset- it is a freakish outlier and breaks the model
#(ws3_yearsums[ws3_yearsums$Cells_flowing == max(ws3_yearsums$Cells_flowing),])
ws3_yearsums[which.max(ws3_yearsums$Cells_flowing),]

#also exclude first and last years
ws3_yearsums <- ws3_yearsums[-(which(ws3$Date == "1957-10-01")),]
ws3_yearsums <- ws3_yearsums[-(which(ws3_yearsums$year == 2022)),]
#plot of yearly CO2 evasion for W3


#adding sens slope
p_load(mblm, Kendall)
sen <- function(formula, dataframe, weights = NULL) {
  mblm::mblm(formula, dataframe)
}
#problem was having duplicate years
blest <- ws3_yearsums %>% 
  dplyr::select(WS, year, yearly_sum) %>% 
  unique()

ggplot(blest,
       aes(x = year, y = yearly_sum)) +
  geom_line() +
  geom_point(size = 2) +
  theme_classic() +
  facet_wrap(~WS, scales = "free_y")+
  geom_smooth(method = sen, se = FALSE)+#, aes(color = "blue")) +
  #scale_colour_manual(name=" ", values=c("blue"),labels = "Sen's Slope")+

  labs(title = expression("Yearly CO"["2"]~" evasion, W3"),
       subtitle = "p = ",
       x = "Year",
       y = expression(CO[2] ~ " (g)"))

```

Find where expanded channels reach into rock outcrops and shallow soil
```{r}
#find where expanded channels reach into rocky outcrops and shallow soil


#read in soil model
soil_map_path <- "./HB/HBsoils.tif"
#twi calculated in script topmodel_fromscratch_2_23_23.Rmd
soil <- raster(soil_map_path)
crs(soil) <- 26919

#symbology for soils
labels <- c("Bh Podzol",
            "Bhs Podzol",
            "Bimodal Podzol",
            "E Podzol",
            "Wetland Histosol",
            "Aquept",
             "Bedrock Histosol",
            "Typical Podzol"
            )

colors <- c("#55FF00",
            "#734C00",
            "#267300",
            "#CCCCCC",
            "#004DA8",
            "#00C5FF",
            "black",
            "#FFFF73"
            )


breaks <- c(1,2,3,4,5,6,7,8)
tmap_mode("view")
tm_shape(soil, raster.downsample = FALSE)+
  tm_raster(style = "cat", #fixed problem by specifying style
            palette = colors, labels = labels, breaks = breaks)

```

```{r}
growing_szn <- read_csv("growing_szn.csv")
growing_szn <- growing_szn[,3:7]



test <- willit(log(twi3), 30)
plot(test)
test[test < 0.9] <- NA
test[test >= 0.9] <- 1

plot(test)
r.new = resample(w3_rast, test, "bilinear")


diff <- w3_rast + test
plot(r.new)

```
  
```{r}
#just do watersheds 3, 6, 7, 8
twi_output <- "./HB/5m hydro enforced DEM/TWI_andotherlayers/twi.tif"
twi <- raster(twi_output)

w3 <- sheds %>% filter(WS == "WS3")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w3)
w3_net <- mask(whole_crop, w3)
twi_crop <- crop(twi, w3)
w3_twi <- mask(twi_crop, w3)

w6 <- sheds %>% filter(WS == "WS6")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w6)
w6_net <- mask(whole_crop, w6)
twi_crop <- crop(twi, w6)
w6_twi <- mask(twi_crop, w6)

w7 <- sheds %>% filter(WS == "WS7")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w7)
w7_net <- mask(whole_crop, w7)
twi_crop <- crop(twi, w7)
w7_twi <- mask(twi_crop, w7)

w8 <- sheds %>% filter(WS == "WS8")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w8)
w8_net <- mask(whole_crop, w8)
twi_crop <- crop(twi, w8)
w8_twi <- mask(twi_crop, w8)



```

```{r}
w3 <- sheds %>% filter(WS == "WS8")
whole[is.na(whole[])] <- 0 
whole_crop <- crop(whole, w3)
w3_net <- mask(whole_crop, w3)
twi_crop <- crop(twi, w3)
w3_twi <- mask(twi_crop, w3)
plot(w3_net)

test <- willit(log(w3_twi), 30)
test[test < 0.9] <- NA
test[test >= 0.9] <- 1
r.new = resample(w3_net, test, "bilinear")

x <- mask(B, A)




  tm_shape(soil)+
  tm_raster(palette = colors, labels = labels, breaks = breaks)+
    tm_shape(test)+

  tm_raster(palette = "red")
#w3- anything above 40
#ws6- anything above 45
#ws7- anything above 50
#ws8- anything above 30
```

Number of times streams lick rocks per year
```{r}
data3 <- growing_szn %>% filter(WS == 3) %>% 
  filter(Q >= 40)
data6 <- growing_szn %>% filter(WS == 6) %>% 
  filter(Q >= 45)
data7 <- growing_szn %>% filter(WS == 7) %>% 
  filter(Q >= 50)
data8 <- growing_szn %>% filter(WS == 8) %>% 
  filter(Q >= 30)

data_all <- rbind(data3, data6)
data_all <- rbind(data_all, data7)
data_all <- rbind(data_all, data8) %>% 
  mutate(year = year(Date)) %>% 
  group_by(year, WS)%>%
    summarise(Count = n())

ggplot(data_all)+
  geom_col(aes(x = year, y = Count), fill = "black")+
  facet_wrap(~WS, )+
  labs(title = "Number of times streams lick rocks per year")+
  theme_classic()

ks8 <- filter(data_all, WS == 8)
#run ks test to see if it is evenly distributed through time
ks.test(ks8$year, "punif", min=1969, max=2021)
#pvalue is greater than 0.05, accept the null hypothesis that it is evenly distributed through time
ks3 <- filter(data_all, WS == 3)
ks.test(ks3$year, "punif", min=1969, max=2021)
ks7 <- filter(data_all, WS == 7)
ks.test(ks7$year, "punif", min=1969, max=2021)
ks6 <- filter(data_all, WS == 6)
ks.test(ks6$year, "punif", min=1969, max=2021)

```
10/13/23, just had meeting with JP and kevin
- make figure showing percentage of time flowing or log duration of flow in hours for each stream based on model, do for each growing season and see if there are noticeable changes through time
-     Channels might have changed over this time scale
- Develop a more sophisticated way to determine when the channel intersects with shallow rocky soil

```{r}

```

10/31/2023
Creating dataset for my brother to analyze
```{r}
head(mask_logtwi2)
head(ws3_flowing)
head(ws3)
head(ws3_yearsums)
head(blest)

ws3_orig <- ws3
ws3 <- ws3_orig
#sending ws3 dataset, and maybe 
ws3 <- ws3[-(which(ws3$Date == "1957-10-01")),]
ws3$year <- year(ws3$Date)
ws3 <- ws3[-(which(ws3$year == 2022)),]

#send matt blest and ws3 in its current form
ws3 <- dplyr::select(ws3, -Cells_flowing, -Area, -CO2)
ws3 <- dplyr::select(ws3, -Q)

write.csv(blest, "yearlyCO2sum.csv")
write.csv(ws3, "dailyFlowingArea.csv")


```

Statistics with Matt 12/4/23
```{r}
stream <- read.csv("./Data4Matt/yearlyCO2sum.csv")
sa <- read.csv("./Data4Matt/dailyFlowingArea.csv")
sa$Date <- ymd(sa$Date)
sa$WS <- as.factor(sa$WS)
#should remove June 30, 1973 from dataset- it is a freakish outlier and breaks the model
#(ws3_yearsums[ws3_yearsums$Cells_flowing == max(ws3_yearsums$Cells_flowing),])
sa[sa$Date == "2011-08-28",]
sa[sa$Date == "1973-06-30",]

sa[which.max(sa$flowing_area_m2),]
#2011-08-28
sa1 <- sa[-(which(sa$Date == "2011-08-28")),]
sa1[which.max(sa1$flowing_area_m2),]
#1973-06-30
sa2 <- sa1[-(which(sa1$Date == "1973-06-30")),]

sa2$month <- month(sa2$Date)
yearly_avg <- sa2 %>% 
  group_by(WS, year, month) %>% 
  mutate(avg = mean(flowing_area_m2)) %>% 
  ungroup()

ggplot(yearly_avg)+
  geom_line(aes(x = Date, y = avg, color = WS))+
  facet_wrap(~WS, scales = "free_y")+
  theme_classic()+
  labs(x = "Date", 
       y = "Stream Surface Area (m^2)",
       title = "Monthly average Stream surface area through time by watershed")


ggplot(sa2)+
  geom_line(aes(x = Date, y = flowing_area_m2, color = WS))+
  facet_wrap(~WS, scales = "free_y")+
  theme_classic()+
  scale_colour_manual(name=" ", values=c("#662C91",
                                         "#17A398",
                                         "#F58A07",
                                         "#BB342F"))+#,labels = "Sen's Slope")
  labs(x = "Date", 
       y = "Stream Surface Area (m^2)",
       title = "Stream surface area through time by watershed")
  

#base r method
ws3 <- sa2[sa2$WS == 3,]
length(ws3$year[ws3$year == "1958"])
#make into time series
p_load(tsibble)
ts3 <- as.ts(ws3[,c(2,4)])




#tidyverse method
ws3 <- dplyr::filter(stream, WS == "3")

ws3 <- stream[stream$WS == 3,]
ws6 <- stream[stream$WS == 6,]
ws7 <- stream[stream$WS == 7,]
ws8 <- stream[stream$WS == 8,]

#ts(vector, start=, end=, frequency=) 
ts3 <- ts(ws3$yearly_sum, start = 1958, end = 2021)
ts6 <- ts(ws6$yearly_sum, start = 1963, end = 2021)
ts7 <- ts(ws7$yearly_sum, start = 1965, end = 2021)
ts8 <- ts(ws8$yearly_sum, start = 1968, end = 2021)


#PLOT OF JUST ONE YEAR OF DATA
one_year <- filter(sa2, year == 2000)
ggplot(one_year)+
  geom_line(aes(x = Date, y = flowing_area_m2, color = WS))+
  facet_wrap(~WS, scales = "free_y")+
  theme_classic()+
  scale_colour_manual(name=" ", values=c("#662C91",
                                         "#17A398",
                                         "#F58A07",
                                         "#BB342F"))+#,labels = "Sen's Slope")
  labs(x = "Date", 
       y = "Stream Surface Area (m^2)",
       title = "Stream surface area through time by watershed")

```

3/18/24
Doing what Kevin and I talked about with my model runs from Carrie's data
```{r}
sa <- read.csv("./Data4Matt/dailyFlowingArea.csv")

```

