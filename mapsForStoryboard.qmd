---
title: "MapsForStoryboard1"
format: html
editor_options: 
  chunk_output_type: console
---
Not just maps for storyboard but also figures for storyboard

11/13/24
Making more finalized versions of maps for storyboard

1/20/25
Revisiting, and actually working on figures

```{r setup}
#loading packages
library(pacman)
p_load(tidyverse, terra, tidyterra, whitebox, scales, wesanderson, caret, plotly,ggnewscale, sf, rgeoboundaries, elevatr, patchwork, ggspatial)
```
# Figure 1: maps and distributions of topo variables
## Maps
```{r NH-map-HB-location}
#make map of NH, pane to show where hubbard brook is
usa <- rgeoboundaries::geoboundaries("USA", "adm1")
NH <- usa[usa$shapeName == "New Hampshire",]
NH_outline <- vect(NH)
mdt <- get_elev_raster(locations = NH, z = 10, clip = "locations")
plot(mdt)
big <- rast(mdt) %>% 
  crop(NH_outline) %>% 
  mask(NH_outline)
writeRaster(big, "./w3_dems/NH.tif", overwrite = TRUE)

NH_path <- "./w3_dems/NH.tif"
hillshade_out <- "./w3_dems/NH_hillshade.tif"
wbt_hillshade(
  dem = NH_path,
  output = hillshade_out,
)
hill <- rast(hillshade_out)
hill2 <- crop(hill, NH_outline)
hill3 <- mask(hill2, NH_outline)
plot(hill)

#read in shapefil of watershed boundaries for HB
#path to file
HB_bounds <- "./HB/hbef_wsheds/hbef_wsheds.shp"
sheds <- vect(HB_bounds)
sheds <- terra::project(sheds, crs(hill))
plot(sheds)
#create boundaries of HB for showing location in NH
dem <- "./HB/1m hydro enforced DEM/dem1m.tif"
m1 <- rast(dem)
plot(m1)
HB_bounds <- vect(ext(m1, cells=NULL), crs = crs(m1))
HB_bounds <- terra::project(HB_bounds, crs(hill))

plot(HB_bounds)


#use bounds of sheds to crop NH dem
ybounds <- c(43.916,43.96219)
xbounds <- c(-71.80451, -71.69687)
plot(hill, xlim = xbounds, ylim = ybounds)
gauge <- c(43.939574, -71.703100)


NH_map <- ggplot()+
  geom_spatraster(data = hill3)+
  theme_void()+
  theme(legend.position = "")+
  scale_fill_gradientn(colors = c("black", "gray9", "gray48","lightgray", "white"), na.value = NA)+
    new_scale_fill() +
  geom_spatraster(data = big, alpha = 0.5)+
  
  #plot rectangle to show HB extent
      geom_sf(data = HB_bounds, color = "black", alpha = 0, lwd = 1.2) +

    #geom_point(aes(y=43.939574, x=-71.703100), colour="black", pch = 20, size = 8)+
   scale_fill_hypso_c(palette = "dem_screen")
NH_map

ggsave("NH.png", plot = NH_map, scale = 1, limitsize = FALSE, #height = 11,width = 4, units = "in"
       bg = NULL,)

ggplot()+
  geom_spatraster(data = hill3)+
  theme_void()+
  theme(legend.position = "")+
  scale_fill_gradientn(colors = c("black", "gray9", "gray48","lightgray", "white"), na.value = NA)+
    new_scale_fill() +
  geom_spatraster(data = big, alpha = 0.5)+
    geom_sf(data = sheds, fill = "darkslategray3", color = "black", alpha = 0.3) +
   scale_fill_hypso_c(palette = "dem_screen")+
  lims(x = xbounds,
       y = ybounds)
```
```{r whole-Valley}
#use HB dem from previous maps, but just don't crop it, include outline of the whole valley, and the outlines of each study shed
dem <- "./HB/1m hydro enforced DEM/dem1m.tif"
m1 <- rast(dem)
plot(m1)

#old hillshade
valley_hill <- rast("./HB/1m hydro enforced DEM/wall_hillshade.tif")
#old hillshade has a different angle, emphasizes the lineaments in the east better, but new one looks niver
#see if a newly calculated one looks better
hillshade_out <- "./HB/1m hydro enforced DEM/new_hillshade.tif"
wbt_hillshade(
  dem = dem,
  output = hillshade_out,
)
valley_hill2 <- rast(hillshade_out)
plot(valley_hill2)


#get the outlines for each watershed
#W3
w3_shed <- "./w3_dems/w3_shed.tif"
w3_outline <- as.polygons(rast(w3_shed), extent=FALSE)
#FB
fb_shed <- "./fb_dems/fb_shed.tif"
fb_outline <- as.polygons(rast(fb_shed), extent=FALSE)
#ZZ
zz_shed <- "./zz_dems/zz_shed.tif"
zz_outline <- as.polygons(rast(zz_shed), extent=FALSE)



valley_plot <- ggplot()+
  geom_spatraster(data = valley_hill2, maxcell = 5e+05)+#make max cells bigger on final version
  theme_void()+
  theme(legend.position = "")+
  scale_fill_gradientn(colors = c("black", "gray9", "gray48","lightgray", "white"))+
    new_scale_fill() +
  geom_spatraster(data = m1, alpha = 0.5)+
  geom_sf(data = fb_outline, fill = NA, color = "black", alpha = 0.3, lwd = 1.5) +
  geom_sf(data = w3_outline, fill = NA, color = "black", alpha = 0.3, lwd = 1.5) +
  geom_sf(data = zz_outline, fill = NA, color = "black", alpha = 0.3, lwd = 1.5) +

  #geom_sf(data = fb_net, colour = "darkslategray3") +#, lwd = 3) +
    #geom_sf(data = lcc, colour = "midnightblue") + #, pch = 19, size = 6) +
  #geom_sf(data = fb_pour, colour = "black") + #, pch = 8, size = 3) +
   scale_fill_hypso_c(palette = "dem_screen")+#, limits = c(200, 1000))+
  theme(rect = element_rect(fill = "transparent", color = NA))+
  ggspatial::annotation_scale(location = 'tr', pad_x = unit(0.5, "cm"), 
                              pad_y = unit(0.5, "cm")) #, line_width = 3, text_cex = 5, tick_height = 20)

ggsave("valley.png", plot = valley_plot, limitsize = FALSE, units = "in", bg = NULL,)

#combine 3 watershed shapes into one layer, and either label or make distinct colors

```
```{r FB-topography-map}
#read in DEM of whole valley, 1m resolution
dem <- "./HB/1m hydro enforced DEM/dem1m.tif"
m1 <- rast(dem)
plot(m1)

#reading in final format data for summer 23
data_23 <- read_csv("./DataForMary/HB_stic.csv")
#reading in final format data for summer 24
data_24 <- read_csv("./summer2024/STICS2024.csv")

#define the rectangular area that will be shown on final map
#determined for each watershed, from figures4poster script
ybounds <- c(4868850,4869650)
xbounds <- c(279350, 280450)
plot(m1, xlim = xbounds, ylim = ybounds)

#create a SpatExtent from a vector (length=4; order=xmin, xmax, ymin, ymax)
crop1 <- crop(m1, ext(c(xbounds, ybounds)))
plot(crop1)
#save cropped 1m dem to reduce processing time below, and gurantee that everything has the same extent
#writeRaster(crop1, "./fb_dems/1mdem_crop.tif", overwrite = TRUE)
#read in cropped dem
fb_crop <- "./fb_dems/1mdem_crop.tif"

#read in shapefile of stream network shape from ARC file on windows computer
fb_net <- vect("./carrieZigZag/FB_network.shp")
plot(fb_net)

###pour point to define where the watershed boundary is
#manually type coords from windows computer
fb_pour_coords <- data.frame("easting" = 280400,
                             "northing" = 4869120)
#convert to SpatVector object
fb_pour <- vect(fb_pour_coords,
                geom = c("easting", "northing"),
                   crs = crs(m1))
#snap pour point to make sure it lies on flowlines
#fb_pour <- snap(fb_pour, fb_net, tol = 1)

#save to file for use in whitebox functions
fb_pour_filename <- "./fb_dems/fb_pour.shp"
#writeVector(fb_pour, fb_pour_filename, overwrite=TRUE)

####delineate watershed and keep watershed boundary
######
#breach and fill I guess
fb_crop <- "./fb_dems/1mdem_crop.tif"

fb_breached <- "./fb_dems/1mdem_breach.tif"
wbt_breach_depressions_least_cost(
  dem = fb_crop,
  output = fb_breached,
  dist = 1,
  fill = TRUE)

fb_filled <- "./fb_dems/1mdem_fill.tif"
wbt_fill_depressions_wang_and_liu(
  dem = fb_breached,
  output = fb_filled
)
#calculate flow accumulation and direction
fb_flowacc <- "./fb_dems/1mdem_fb_flowacc.tif"
wbt_d8_flow_accumulation(input = fb_filled,
                         output = fb_flowacc)
plot(rast(fb_flowacc))
fb_d8pt <- "./fb_dems/1mdem_fb_d8pt.tif"
wbt_d8_pointer(dem = fb_filled,
               output = fb_d8pt)
plot(rast(fb_d8pt))


#delineate streams
fb_streams <- "./fb_dems/fb_streams.tif"
wbt_extract_streams(flow_accum = fb_flowacc,
                    output = fb_streams,
                    threshold = 8000)
plot(rast(fb_streams))
plot(as.lines((as.polygons(rast(fb_streams)))),
     xlim = c(279800, 279900), ylim = c(4869100,4869200))
#results in weird lines, figure out how to simplify
topo_streams <- as.lines(as.polygons(rast(fb_streams)))

points(lcc)
#snap pour point to streams
fb_pour_snap <- "./fb_dems/fb_pour_snap.shp"
wbt_jenson_snap_pour_points(pour_pts = fb_pour_filename,
                            streams = fb_streams,
                            output = fb_pour_snap,
                            snap_dist = 10)
fb_pour_snap_read <- vect("./fb_dems/fb_pour_snap.shp")
plot(rast(fb_streams), 
     xlim = c(280200, 280410),
     ylim = c(4869300, 4869000))
points(fb_pour_snap_read, pch = 1)

fb_shed <- "./fb_dems/fb_shed.tif"
wbt_watershed(d8_pntr = fb_d8pt,
              pour_pts = fb_pour_snap,
              output = fb_shed)

plot(rast(fb_shed))
#convert raster of watershed area to vector for final mapping
fb_outline <- as.polygons(rast(fb_shed), extent=FALSE)
plot(fb_outline)

#get sensor locations from STIC data, format
locs <- data_23 %>% 
  filter(wshed == "FB") %>% 
  select(ID, lat, long) %>% 
  unique()
#convert STIC data to a SpatVector data format
locs_shape <- vect(locs, 
                   geom=c("long", "lat"), 
                   crs = "+proj=longlat +datum=WGS84")
plot(locs_shape)
#reproject coordinates from WGS84 to NAD83 19N, which is the projection of raster
lcc <- terra::project(locs_shape, crs(m1))
plot(lcc)

#assign destination for hillshade calculation
hillshade_out <- "./fb_dems/1mdem_hillshade.tif"
wbt_hillshade(
  dem = fb_crop,
  output = hillshade_out,
)
hill <- rast(hillshade_out)
plot(hill)

fb_slope <- "./fb_dems/1mdem_slope.tif"
wbt_slope(dem = fb_filled,
          output = fb_slope,
          units = "degrees")

fb_twi <- "./fb_dems/1mdem_twi.tif"
wbt_wetness_index(sca = fb_flowacc, #flow accumulation
                  slope = fb_slope,
                  output = fb_twi)


#final plot with cropped hillshade and dem, STIC locations, watershed boundary, and stream network.
fb_map <- ggplot()+
  geom_spatraster(data = hill)+
  theme_void()+
  theme(legend.position = "")+
  scale_fill_gradientn(colors = c("black", "gray9", "gray48","lightgray", "white"))+
    new_scale_fill() +
  geom_spatraster(data = crop1, alpha = 0.5)+
    geom_sf(data = fb_outline, fill = NA, color = "black", alpha = 0.3) +#, lwd = 3) +
  geom_sf(data = fb_net, colour = "darkslategray3") +#, lwd = 3) +
    geom_sf(data = lcc, colour = "midnightblue") + #, pch = 19, size = 6) +
  geom_sf(data = fb_pour, colour = "black") + #, pch = 8, size = 3) +
   scale_fill_hypso_c(palette = "dem_screen", limits = c(200, 1000))+
  theme(rect = element_rect(fill = "transparent", color = NA))+
  ggspatial::annotation_scale(location = 'tr', pad_x = unit(0.5, "cm"), 
                              pad_y = unit(0.5, "cm")) #, line_width = 3, text_cex = 5, tick_height = 20)

fb_map

#Map of TWI not included
# twi_output <- "./fb_dems/10mdem_twi.tif"
# 
# plot(rast(twi_output), xlim = xbounds, ylim = ybounds)
# ggplot()+
#   geom_spatraster(data = rast(twi_output))+
#   theme_void()+
#   lims(x = xbounds, y = ybounds)+
#   theme(legend.position = "")+
#     geom_sf(data = fb_outline, fill = NA, color = "black", alpha = 0.3) +#, lwd = 3) +
#     geom_sf(data = lcc, colour = "midnightblue", pch = 1) + #, pch = 19, size = 6) +
#    scale_fill_hypso_c(palette = "arctic")+
#   theme(rect = element_rect(fill = "transparent", color = NA))+
#   ggspatial::annotation_scale(location = 'tr', pad_x = unit(0.5, "cm"), 
#                               pad_y = unit(0.5, "cm"))


```
```{r try-NAIP-UNFINISHED}
#read in NAIP imagery for true color composite image
color <- sprc(c("./HB/Original zips/m_4307102_ne_19_030_20230823.jp2",
       "./HB/Original zips/m_4307102_nw_19_030_20230823.jp2",
       "./HB/Original zips/m_4307102_se_19_030_20230823.jp2",
       "./HB/Original zips/m_4307102_sw_19_030_20230823.jp2",
       "./HB/Original zips/m_4307103_ne_19_030_20230823.jp2",
       "./HB/Original zips/m_4307103_nw_19_030_20230823.jp2"))

stackT <- stack("./HB/Original zips/m_4307103_nw_19_030_20230823.jp2")


plot(rast("./HB/Original zips/m_4307103_nw_19_030_20230823.jp2"))
naip_csf_br <- brick(naip_csf_st)
inMemory(naip_csf_br)

plotRGB(naip_csf_br,
        r = 1, g = 2, b = 3,
        main = "RGB image \nColdsprings fire scar")
big_image <- merge(color)
```
## Topo variables
```{r topo-distributions}
#get the areas of each watershed, and the whole valley
#delineate shed and stream using 3, 5, 10m dem, then plot distribution of elevation and TWI

dem <- "./HB/1m hydro enforced DEM/dem1m.tif"
m1 <- rast(dem)
m10 <- aggregate(m1, 3)
#plot(m10)

#save raster, because whitebox wants it is a files location instead of an object in R
writeRaster(m10, "./HB/1m hydro enforced DEM/dem3m.tif", overwrite = TRUE)
m3_path <- "./HB/1m hydro enforced DEM/dem3m.tif"

fb_elev <- m10 %>% 
  crop(fb_outline) %>% 
  mask(fb_outline)
zz_elev <- m10 %>% 
  crop(zz_outline) %>% 
  mask(zz_outline)
w3_elev <- m10 %>% 
  crop(w3_outline) %>% 
  mask(w3_outline)

plot(fb_elev)
summary(zz_elev$dem1m)
summary(fb_elev$dem1m)
summary(w3_elev$dem1m)

hist(zz_elev$dem1m)
hist(fb_elev$dem1m)
hist(w3_elev$dem1m)

zz_dist <- as_tibble(data.frame("elev" = zz_elev$dem1m, "site" = "zz"))
fb_dist <- as_tibble(data.frame("elev" = fb_elev$dem1m, "site" = "fb"))
w3_dist <- as_tibble(data.frame("elev" = w3_elev$dem1m, "site" = "w3"))

all_dist <- rbind(zz_dist, fb_dist, w3_dist)

ggplot(all_dist)+
  geom_boxplot(aes(x=site, y=dem1m))

#now calculate and display the distribution of TWI for each watershed as boxplot
#calculate TWI for the whole valley, then just extract like above
#fill and breach 3m dem
breach_output <- "./HB/1m hydro enforced DEM/dem3m_breach.tif"
wbt_breach_depressions_least_cost(
  dem = m3_path,
  output = breach_output,
  dist = 3,
  fill = TRUE)

fill_output <- "./HB/1m hydro enforced DEM/dem3m_fill.tif"
wbt_fill_depressions_wang_and_liu(
  dem = breach_output,
  output = fill_output
)
flowacc_output <- "./HB/1m hydro enforced DEM/dem3m_flowacc.tif"
wbt_d_inf_flow_accumulation(input = fill_output,
                            output = flowacc_output,
                            out_type = "Specific Contributing Area")
slope_output <- "./HB/1m hydro enforced DEM/dem3m_slope.tif"
wbt_slope(dem = fill_output,
          output = slope_output,
          units = "degrees")
twi_output <- "./HB/1m hydro enforced DEM/dem3m_twi.tif"
wbt_wetness_index(sca = flowacc_output, #flow accumulation
                  slope = slope_output,
                  output = twi_output)

#crop and mask TWI by each of my watersheds
twi_valley <- rast(twi_output)
fb_twi <- twi_valley %>% 
  crop(fb_outline) %>% 
  mask(fb_outline)
zz_twi <- twi_valley %>% 
  crop(zz_outline) %>% 
  mask(zz_outline)
w3_twi <- twi_valley %>% 
  crop(w3_outline) %>% 
  mask(w3_outline)

#convert raster values to tibble
zz_tib <- as_tibble(data.frame("twi" = zz_twi$dem3m_twi, "site" = "zz"))
fb_tib <- as_tibble(data.frame("twi" = fb_twi$dem3m_twi, "site" = "fb"))
w3_tib <- as_tibble(data.frame("twi" = w3_twi$dem3m_twi, "site" = "w3"))

all_twi <- rbind(zz_tib, fb_tib, w3_tib)

ggplot(all_twi)+
  geom_boxplot(aes(x=site, y=dem3m_twi))

ggplot(all_twi)+
  geom_histogram(aes(y=after_stat(density),
                     fill=site, 
                     x=(dem3m_twi)), 
                 alpha=0.6, position="identity")
ggplot(all_twi)+
  geom_histogram(aes(y=after_stat(density),
                     fill=site, 
                     x=log(dem3m_twi)))

#create plots of distribution
```

# Figure 3: Distribution of flow permanence and duration of flow
## Flow Permanence
```{r prepare-discharge}
#from TestingFrameworks script

#read in discharge from W3-- input to Carrie's model, discharge in L/s
#q <- read_csv("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-hbr.1.17&entityid=efc477b3ef1bb3dd8b9355c9115cd849")
#write.csv(q, "HB_5minQ.csv")
q <- read_csv("HB_5minQ.csv")
#input discharge needs to be in mm/day?
#reference to understand difference between daily mean and instantaneous streamflow:
#https://hydrofunctions.readthedocs.io/en/master/notebooks/DailyMean_vs_Instant.html

#creating minute column, used to filter out higher temporal resolution measurements for plotting
data_23$mins <- minute(data_23$datetime)
data_24$mins <- minute(data_24$datetime)

#find the range of dates that I need discharge for
start <- min(data_23$datetime)
stop <- max(data_23$datetime)

#filtering discharge down to the range of dates
q_23 <- q %>% 
  filter(DATETIME > start & DATETIME < stop) %>% 
  #convert to mm/day.
  #converting instantaneous streamflow to mm/day by taking measurement, and scaling   it up as if that was the discharge for the whole day. It is not, it is just at that   moment, but should fix any units/order of magnitude issues
  mutate("Q_mm_day" = Discharge_ls * 0.001 * 86400 / 420000 * 1000) 
q_23$mins <- minute(q_23$DATETIME)

#removing times that are not coincident with STIC observations
q_23_f <- filter(q_23, mins %in% c(0, 30))

ggplot(q_23_f, aes(x  = DATETIME, y = Q_mm_day))+
  geom_line()+
  labs(title = "Discharge from W3, July to Nov 2023",
       x = "",
       y = "Instantaneous Q (mm/day)")+
  theme_classic()

```
```{r flow-permanence-W3}
#just summer 2023
data_23$binary <- 1
data_23$binary[data_23$wetdry == "dry"] <- 0
#make binary column
data_24$binary <- 1
data_24$binary[data_24$wetdry == "dry"] <- 0

pks_23 <- data_23 %>% 
    mutate(mins = minute(datetime)) %>% 
  filter(wshed == "W3", mins %in% c(0, 30)) %>% 
  select(datetime, ID, lat, long, binary) %>% 
    group_by(ID) %>% 
    #slice_sample(prop = 0.8) %>% 
  rename("DATETIME" = datetime) %>% 
  #left_join(select(q_23_f, c(DATETIME, Q_mm_day)), by = "DATETIME") %>% 
  summarise(pk = sum(binary)/length(binary)) %>% 
  select(ID, pk) %>% 
  ungroup()
#just summer 2024
pks_24 <- data_24 %>% 
    mutate(mins = minute(datetime)) %>% 
  filter(wshed == "W3", mins %in% c(0, 30)) %>% 
  select(datetime, number, lat, long, binary) %>% 
    group_by(number) %>% 
  rename("DATETIME" = datetime, "ID" = number) %>% 
  #left_join(select(q_23_f, c(DATETIME, Q_mm_day)), by = "DATETIME") %>% 
  summarise(pk = sum(binary)/length(binary)) %>% 
  select(ID, pk) %>% 
  ungroup()

both <- inner_join(pks_23, pks_24, by = "ID")
ggplot()+
  geom_point(data = both,aes(x = pk.x, y = pk.y))+
  geom_abline(slope=1, intercept=0)

#both summers
#just rbind summers 23 and 24
precalc_24 <- data_24 %>% 
    mutate(mins = minute(datetime)) %>% 
  filter(wshed == "W3", mins %in% c(0, 30)) %>% 
  select(datetime, number, lat, long, binary) %>% 
    group_by(number) %>% 
  rename("DATETIME" = datetime, "ID" = number)
  
pks_w3 <- data_23 %>% 
    mutate(mins = minute(datetime)) %>% 
  filter(wshed == "W3", mins %in% c(0, 30)) %>% 
  select(datetime, ID, lat, long, binary) %>% 
    group_by(ID) %>% 
    #slice_sample(prop = 0.8) %>% 
  rename("DATETIME" = datetime) %>%
  rbind(precalc_24) %>% 
  summarise(pk = sum(binary)/length(binary)) %>% 
  select(ID, pk) %>% 
  ungroup() %>% 
  mutate(wshed = "W3")
```
```{r flow-permanence-FB}
#both summers
#just rbind summers 23 and 24
precalc_24 <- data_24 %>% 
    mutate(mins = minute(datetime)) %>% 
  filter(wshed == "FB", mins %in% c(0, 30)) %>% 
  select(datetime, number, lat, long, binary) %>% 
    group_by(number) %>% 
  rename("DATETIME" = datetime, "ID" = number)
  
pks_fb <- data_23 %>% 
    mutate(mins = minute(datetime)) %>% 
  filter(wshed == "FB", mins %in% c(0, 30)) %>% 
  select(datetime, ID, lat, long, binary) %>% 
    group_by(ID) %>% 
    #slice_sample(prop = 0.8) %>% 
  rename("DATETIME" = datetime) %>%
  rbind(precalc_24) %>% 
  summarise(pk = sum(binary)/length(binary)) %>% 
  select(ID, pk) %>% 
  ungroup() %>% 
  mutate(wshed = "FB")
```
```{r flow-permanence-ZZ}
precalc_24 <- data_24 %>% 
    mutate(mins = minute(datetime)) %>% 
  filter(wshed == "ZZ", mins %in% c(0, 30)) %>% 
  select(datetime, number, lat, long, binary) %>% 
    group_by(number) %>% 
  rename("DATETIME" = datetime, "ID" = number)
  
pks_zz <- data_23 %>% 
    mutate(mins = minute(datetime)) %>% 
  filter(wshed == "ZZ", mins %in% c(0, 30)) %>% 
  select(datetime, ID, lat, long, binary) %>% 
    group_by(ID) %>% 
    #slice_sample(prop = 0.8) %>% 
  rename("DATETIME" = datetime) %>%
  rbind(precalc_24) %>% 
  summarise(pk = sum(binary)/length(binary)) %>% 
  select(ID, pk) %>% 
  ungroup() %>% 
  mutate(wshed = "ZZ")
```
```{r combine-boxplot}
rbind(pks_w3, pks_fb, pks_zz) %>% 
  ggplot(aes(x = wshed, y = pk))+
  geom_boxplot()+
  geom_jitter(width = 0.1, alpha = 0.5)+
  theme_classic()+
  labs(title = "Distributions of Flow Permanence",
       x = "Watershed",
       y = "Flow Permanence")
```

```{r}
#what is the fewest number of times you would need to observe a location to determine the actual local persistency?
#what about if you visited over a range of wetness conditions? Like every 10th quartile
```

## Average Duration of Flow
```{r dof-w3}
#successfully calculating the average duration of flow for an event
bind23 <- data_23 %>% 
  select(datetime, ID, wshed, binary, mins)
bind24 <- data_24 %>% 
  select(datetime, number, wshed, binary, mins) %>% 
  rename("ID" = number)

dof_w3 <- rbind(bind23, bind24) %>% 
  filter(wshed == "W3", mins %in% c(0, 30)) %>% 
  select(datetime, ID, binary) %>% 
  mutate(group = data.table::rleid(binary)) %>%
  group_by(group, ID) %>%
  summarise(state = first(binary), 
            timeperiod = dplyr::last(datetime) - dplyr::first(datetime)) %>% 
  mutate(timeperiod = as.numeric(timeperiod, units = "days")) %>% 
  group_by(ID) %>% 
  filter(state == 1) %>% 
  summarise(avg_days_flowing = mean(timeperiod)) %>% 
  mutate(wshed = "W3")

```
```{r dof-fb}
dof_fb <- rbind(bind23, bind24) %>% 
  filter(wshed == "FB", mins %in% c(0, 30)) %>% 
  select(datetime, ID, binary) %>% 
  mutate(group = data.table::rleid(binary)) %>%
  group_by(group, ID) %>%
  summarise(state = first(binary), 
            timeperiod = dplyr::last(datetime) - dplyr::first(datetime)) %>% 
  mutate(timeperiod = as.numeric(timeperiod, units = "days")) %>% 
  group_by(ID) %>% 
  filter(state == 1) %>% 
  summarise(avg_days_flowing = mean(timeperiod)) %>% 
  mutate(wshed = "FB") %>% 
  #remove outlier left out over winter
  filter(ID != 32)
```
```{r dof-zz}
dof_zz <- rbind(bind23, bind24) %>% 
  filter(wshed == "ZZ", mins %in% c(0, 30)) %>% 
  select(datetime, ID, binary) %>% 
  mutate(group = data.table::rleid(binary)) %>%
  group_by(group, ID) %>%
  summarise(state = first(binary), 
            timeperiod = dplyr::last(datetime) - dplyr::first(datetime)) %>% 
  mutate(timeperiod = as.numeric(timeperiod, units = "days")) %>% 
  group_by(ID) %>% 
  filter(state == 1) %>% 
  summarise(avg_days_flowing = mean(timeperiod)) %>% 
  mutate(wshed = "ZZ")
```
```{r combine-boxplot}
rbind(dof_w3, dof_fb, dof_zz) %>% 
  ggplot(aes(x = wshed, y = (avg_days_flowing)))+
  geom_boxplot()+
  geom_jitter(width = 0.1, alpha = 0.5)+
  theme_classic()+
  labs(title = "Distributions of Average Duration of Flow",
       x = "Watershed",
       y = "Duration of Flow (days)")

```

#Figure 4: How often does the network wet up, dry down, etc?
```{r}
test <- data_23 %>% 
  filter(wshed == "W3", mins %in% c(0, 30)) %>% 
  select(datetime, ID, binary) %>% 
    group_by(ID) %>% 
  rename("DATETIME" = datetime) %>% 
  left_join(select(q_23_f, c(DATETIME, Q_mm_day)), by = "DATETIME") %>% 
  #filter(ID == 1)%>% 
  mutate(lagged = lag(binary),
         transition = (binary - lagged)) #%>% 
  filter(transition %in% c(-1, 1))

test$state_change <- "none"
test$state_change[test$transition == -1] <- "wetting"
test$state_change[test$transition == 1] <- "drying"
```
First thing to try that I have tried before: determine all unique combinations of wet and dry sensors
```{r}
#find all unique combinations of wet and dry sensors
hush2 <- rbind(bind23, bind24) %>%
  filter(wshed == "W3", mins %in% c(0, 30)) %>%
  select(datetime, binary, ID) %>%
  pivot_wider(names_from = ID, values_from = binary)

hush3 <- hush2[1:5,-1]
hush3
hush3[-1, ]

hush3[-5,] - hush3[-1, ]

# xy.list <- as.list(as.data.frame(t(hush2[,-1])))
# length(xy.list)
# length(unique(data$datetime))
# #unique combinations of flow
# length(unique(xy.list))

#perhaps subset it so that I am working with one pair of consecutive sensors at a time
hush3[-5,15:17] - hush3[-1, 15:17]
hush3[,15:17]

#how often does 17 activate before 16?
#filter to every time that 17 transitions to flowing- value of -1
l <- 20 #length of time
hush3 <- hush2[1:l,-1] #get the number of time steps equal to l, get rid of time id col

hush3[-l,16:17] - hush3[-1, 16:17] #find the change with lagged cols, output does not have last delta

#find every time that 17 is -1
hush4 <- hush3[-l,16:17] - hush3[-1, 16:17]
colnames(hush4) <- c("up", "down")

hush4

#how often does the upstream sensor go to -1 after the downstream sensor?
require(data.table)
data.table:::duplist(hush4[, 3:5]) 

hush4 %>% 
mutate(group = data.table::rleid(down)) %>%
  group_by(group) %>%
  summarise(state = first(down),
            rows = length(group)) #%>% 
  mutate(timeperiod = as.numeric(timeperiod, units = "days"))

#how can I calculate seqeunce of activation?
data <- data.frame(
  Var1 = c(1, 0, 1, 1, 0),
  Var2 = c(0, 1, 1, 0, 1),
  Var3 = c(1, 1, 1, 1, 0)
)

target_sequence <- c(1, 0, 1)

matches <- apply(data, 1, function(row) all(row == target_sequence))
count <- sum(matches)
proportion <- count / nrow(data)

cat("Number of matches:", count, "\n")
cat("Proportion of matches:", proportion, "\n")



#one idea- fit a logistic regression of every sensor to every other sensor. If a sensor is always flowing when another is, it would be a good predictor
mod <- hush2[,16:17]
colnames(mod) <- c("up", "down")

mod2 <- hush2
colnames(mod2) <- as.character(paste0("r_",colnames(hush2)))

model <- glm(r_1 ~.,family=binomial(link='logit'),data=mod2)
summary(model)
```
```{r}
#how often does x activate after y?
p_load(zoo)

data <- data.frame(
  Var1 = c(1, 0, 1, 1, 0, 1, 1),
  Var2 = c(0, 1, 1, 0, 1, 0, 0),
  Var3 = c(1, 1, 1, 1, 0, 1, 1)
)
target_sequence <- matrix(
  c(1, 0, 1,
    0, 1, 1),
  nrow = 2, byrow = TRUE
)

# Flatten the target sequence for comparison
target_vector <- as.vector(t(target_sequence))

# Use rollapply to create sliding windows
windows <- rollapply(data, width = nrow(target_sequence), by.column = FALSE, FUN = function(x) as.vector(t(x)))

# Check for matches
matches <- apply(windows, 1, function(window) all(window == target_vector))

# Get indices of matches
match_indices <- which(matches)

cat("Matching sequence found at indices:", match_indices, "\n")


#now test on my data
mod3 <- select(mod2,r_15, r_16, r_17)
target_sequence <- matrix(
  c(
    0, 0, 1,
    0, 1, 1,
    1, 1, 1),
  nrow = 3, byrow = TRUE
)
target_vector <- as.vector(t(target_sequence))

# Use rollapply to create sliding windows
windows <- rollapply(mod3, width = nrow(target_sequence), by.column = FALSE, FUN = function(x) as.vector(t(x)))

# Check for matches
matches <- apply(windows, 1, function(window) all(window == target_vector))

# Get indices of matches
match_indices <- which(matches)
length(match_indices)

###another attempt

# Example data
mod3 <- select(mod2,r_15, r_16, r_17)


# Define window size
window_size <- 6

# Create sliding windows
windows <- rollapply(
  mod3,
  width = window_size,
  by.column = FALSE,
  FUN = function(x) paste(as.vector(t(x)), collapse = "")
)

# Count and sort sequences
sequence_counts <- table(windows)
sorted_counts <- sort(sequence_counts, decreasing = TRUE)

# Get most common sequence
most_common_sequence <- names(sorted_counts)[1]
cat("Most common sequence:", most_common_sequence, "\n")
cat("Frequency:", sorted_counts[1], "\n")

# Display all sequences and their frequencies
sequence_df <- as.data.frame(sorted_counts, stringsAsFactors = FALSE)
colnames(sequence_df) <- c("Sequence", "Frequency")
print(sequence_df)

```

```{r}
#find the most common sequence of activation during the rising limb, or times when slope of discharge is positive
mod3 <- drop_na(mod2[,-1])
no_dupes <- mod3 %>%
  filter(row_number() == 1 | !apply(. == lag(.), 1, all))
#make it so that there cannot be a sequence without change

# Define window size
window_size <- 4

# Create sliding windows
windows <- rollapply(
  no_dupes,
  width = window_size,
  by.column = FALSE,
  FUN = function(x) paste(as.vector(t(x)), collapse = "")
)

# Count and sort sequences
sequence_counts <- table(windows)
sorted_counts <- sort(sequence_counts, decreasing = TRUE)

# Display all sequences and their frequencies
sequence_df <- as.data.frame(sorted_counts, stringsAsFactors = FALSE)
colnames(sequence_df) <- c("Sequence", "Frequency")
View(sequence_df)
```

```{r}
#convert this result into a plot
#number of panes dictated by window size
window_size

number_in_list <- 4
#left join the sequence to the locations of the sensors and plot
head(sequence_df)

status <- data.frame("ID" = as.numeric(rep(substr(colnames(no_dupes), 3,4),window_size)),
                     "status" = unlist(strsplit(sequence_df$Sequence[number_in_list], split = "")),
                     "timestep" = c(rep(1, 31), rep(2, 31), rep(3, 31), rep(4, 31)))

#get sensor locations from STIC data, format
locs <- data_23 %>% 
  filter(wshed == "W3") %>% 
  select(ID, lat, long) %>% 
  unique() %>% 
  left_join(status, by = "ID")
#convert STIC data to a SpatVector data format
locs_shape <- vect(locs, 
                   geom=c("long", "lat"), 
                   crs = "+proj=longlat +datum=WGS84")
#reproject coordinates from WGS84 to NAD83 19N, which is the projection of raster
lcc <- terra::project(locs_shape, crs(m1))

ggplot()+
  geom_spatraster(data = hill)+
  theme_void()+
  #theme(legend.position = "")+
  scale_fill_gradientn(colors = c("black", "gray9", "gray48","lightgray", "white"))+
    new_scale_fill() +
  geom_spatraster(data = crop1, alpha = 0.5)+
    geom_sf(data = w3_outline, fill = NA, color = "black", alpha = 0.3)+
  geom_sf(data = w3_net, colour = "darkslategray3") +
    geom_sf(data = lcc, aes(colour = status), pch = 19) +
  facet_wrap(~timestep)+
   scale_fill_hypso_c(palette = "dem_screen" , limits = c(200, 1000))+
  theme(rect = element_rect(fill = "transparent", color = NA))
```

```{r w3-map}
#read in DEM of whole valley, 1m resolution
dem <- "./HB/1m hydro enforced DEM/dem1m.tif"
m1 <- rast(dem)
plot(m1)

#get sensor locations from STIC data, format
locs <- data_23 %>% 
  filter(wshed == "W3") %>% 
  select(ID, lat, long) %>% 
  unique()
#convert STIC data to a SpatVector data format
locs_shape <- vect(locs, 
                   geom=c("long", "lat"), 
                   crs = "+proj=longlat +datum=WGS84")
plot(locs_shape)
#reproject coordinates from WGS84 to NAD83 19N, which is the projection of raster
lcc <- terra::project(locs_shape, crs(m1))
plot(lcc)
#define the rectangular area that will be shown on final map
ybounds <- c(4870350,4871350)
xbounds <- c(281350, 282150)
plot(m1, xlim = xbounds, ylim = ybounds)
points(lcc)

#create a SpatExtent from a vector (length=4; order=xmin, xmax, ymin, ymax)
crop1 <- crop(m1, ext(c(xbounds, ybounds)))
plot(crop1)
#save cropped 1m dem to reduce processing time below, and gurantee that everything has the same extent
writeRaster(crop1, "./w3_dems/1mdem_crop.tif", overwrite = TRUE)
#read in cropped dem
w3_crop <- "./w3_dems/1mdem_crop.tif"

#read in shapefile of stream network shape from ARC file on windows computer
w3_net <- vect("./carrieZigZag/w3_network.shp")
plot(w3_net)

###pour point to define where the watershed boundary is
#manually type coords from windows computer
 
 
w3_pour_coords <- data.frame("easting" = 281537.46,
                             "northing" = 4870424.50)
#convert to SpatVector object
w3_pour <- vect(w3_pour_coords,
                geom = c("easting", "northing"),
                   crs = crs(m1))
#snap pour point to make sure it lies on flowlines
#fb_pour <- snap(fb_pour, fb_net, tol = 1)

#save to file for use in whitebox functions
w3_pour_filename <- "./w3_dems/w3_pour.shp"
writeVector(w3_pour, w3_pour_filename, overwrite=TRUE)

####delineate watershed and keep watershed boundary
#breach and fill I guess
w3_crop <- "./w3_dems/1mdem_crop.tif"

w3_breached <- "./w3_dems/1mdem_breach.tif"
wbt_breach_depressions_least_cost(
  dem = w3_crop,
  output = w3_breached,
  dist = 1,
  fill = TRUE)

w3_filled <- "./w3_dems/1mdem_fill.tif"
wbt_fill_depressions_wang_and_liu(
  dem = w3_breached,
  output = w3_filled
)
#calculate flow accumulation and direction
w3_flowacc <- "./w3_dems/1mdem_w3_flowacc.tif"
wbt_d8_flow_accumulation(input = w3_filled,
                         output = w3_flowacc)
plot(rast(w3_flowacc))
w3_d8pt <- "./w3_dems/1mdem_w3_d8pt.tif"
wbt_d8_pointer(dem = w3_filled,
               output = w3_d8pt)
plot(rast(w3_d8pt))


#delineate streams
w3_streams <- "./w3_dems/w3_streams.tif"
wbt_extract_streams(flow_accum = w3_flowacc,
                    output = w3_streams,
                    threshold = 8000)
plot(rast(w3_streams))
points(lcc)
#snap pour point to streams
w3_pour_snap <- "./w3_dems/w3_pour_snap.shp"
wbt_jenson_snap_pour_points(pour_pts = w3_pour_filename,
                            streams = w3_streams,
                            output = w3_pour_snap,
                            snap_dist = 10)
w3_pour_snap_read <- vect("./w3_dems/w3_pour_snap.shp")
plot(rast(w3_streams), 
     xlim = c(281400, 282000),
     ylim = c(4870400, 4870800))
points(w3_pour_snap_read, pch = 1)

w3_shed <- "./w3_dems/w3_shed.tif"
wbt_watershed(d8_pntr = w3_d8pt,
              pour_pts = w3_pour_snap,
              output = w3_shed)

plot(rast(w3_shed))
#convert raster of watershed area to vector for final mapping
w3_outline <- as.polygons(rast(w3_shed), extent=FALSE)
plot(w3_outline)



#assign destination for hillshade calculation
hillshade_out <- "./w3_dems/1mdem_hillshade.tif"
wbt_hillshade(
  dem = w3_crop,
  output = hillshade_out,
)
hill <- rast(hillshade_out)
plot(hill)

#final plot with cropped hillshade and dem, STIC locations, watershed boundary, and stream network.





```

Whenever there is a change in state, does it follow the wetting up, drying down, or flow permanence hypothesis?

```{r}
#testing pairs of sensors
#filter to two upstream/downstream sensors
mod3 <- drop_na(mod2[,-1]) %>% select("r_22", "r_23")
no_dupes <- mod3 %>%
  filter(row_number() == 1 | !apply(. == lag(.), 1, all))
#make it so that there cannot be a sequence without change

# Define window size
window_size <- 2

# Create sliding windows
windows <- rollapply(
  no_dupes,
  width = window_size,
  by.column = FALSE,
  FUN = function(x) paste(as.vector(t(x)), collapse = "")
)

# Count and sort sequences
sequence_counts <- table(windows)
sorted_counts <- sort(sequence_counts, decreasing = TRUE)

# Display all sequences and their frequencies
sequence_df <- as.data.frame(sorted_counts, stringsAsFactors = FALSE)
colnames(sequence_df) <- c("Sequence", "Frequency")
View(sequence_df)

total <- sum(sequence_df$Frequency)
#write some way to score the sequence_df
#award one point for one of these configs:
supports <- c("0001", "0011", "0111", "1110", "1100")

sub <- filter(sequence_df, Sequence %in% supports)
points <- sum(sub$Frequency)

#create output with the total and the sub, also the two input locations

```
Use above chunk to write a function to take an upstream and downstream sensor, and determine what proportion of the times it changes state follow the systematic behavior I am looking for.
```{r define-function}
#testing pairs of sensors
#filter to two upstream/downstream sensors
calc_support <- function(up, down){

mod3 <- input %>% select(up,down, -datetime)
no_dupes <- mod3 %>%
  filter(row_number() == 1 | !apply(. == lag(.), 1, all))
#make it so that there cannot be a sequence without change

# Define window size
window_size <- 2

# Create sliding windows
windows <- rollapply(
  no_dupes,
  width = window_size,
  by.column = FALSE,
  FUN = function(x) paste(as.vector(t(x)), collapse = "")
)

# Count and sort sequences
sequence_counts <- table(windows)
sorted_counts <- sort(sequence_counts, decreasing = TRUE)

# Display all sequences and their frequencies
sequence_df <- as.data.frame(sorted_counts, stringsAsFactors = FALSE)
colnames(sequence_df) <- c("Sequence", "Frequency")
#View(sequence_df)

total <- sum(sequence_df$Frequency)
#write some way to score the sequence_df
#award one point for one of these configs:
supports <- c("0001", "0011", "0111", "1110", "1100", "1101", "0100")
#subset from the 16 possibilities, except it is fewer because
#0000, 1111, 0101, 1010 are removed...

sub <- filter(sequence_df, Sequence %in% supports)
points <- sum(sub$Frequency)

#create output with the total and the sub, also the two input locations
output <- data.frame(up, down, points, total)
return(output)
}

calc_support("r_4", "r_5")
```

Iterating through each pair of sensors, using the upstream sensor as the id, and the downstream sensor as the secondary or dependent. Seeing how often pairs of sensors wet up or dry down relative to each other.
##looping by relative position
```{r looping-W3}
#equivalent to hush 2 from earlier,
#make a new input for each watershed chunk
input <- rbind(bind23, bind24) %>%
  filter(wshed == "W3", mins %in% c(0, 30)) %>%
  select(datetime, binary, ID) %>%
  mutate(ID = paste0("r_",ID)) %>% 
  pivot_wider(names_from = ID, values_from = binary)
#now make loop to loop through all pairs of sensors
routes <- read_csv("w3_flowrouting.csv") %>% 
  rename("up" = drains_from, "down" = drains_to) %>% 
  select(sensor, down) %>% 
  filter(down != 100)

for(x in 1:length(routes$sensor)){
  up <- paste0("r_",routes$sensor[x])
  down <- paste0("r_",routes$down[x])
  
  out <- calc_support(up, down)
  if(x == 1) alldat <- out
  if(x > 1) alldat <- rbind(alldat, out)

}

alldat$prop <- alldat$points/alldat$total
w3_pairs <- alldat
#this shows the proportion of time that pairs of upstream/downstream sensors behave according to the hypothesis of wetting up and drying down
hist(alldat$prop)
```
```{r looping-FB}
#equivalent to hush 2 from earlier,
#make a new input for each watershed chunk
input <- rbind(bind23, bind24) %>%
  filter(wshed == "FB", mins %in% c(0, 30)) %>%
  select(datetime, binary, ID) %>%
  mutate(ID = paste0("r_",ID)) %>% 
  pivot_wider(names_from = ID, values_from = binary)
#now make loop to loop through all pairs of sensors
routes <- read_csv("fb_flowrouting.csv") %>% drop_na() %>% 
  mutate(up = paste0("r_",up),
         down = paste0("r_",down))

for(x in 1:length(routes$up)){
  
  out <- calc_support(routes$up[x], routes$down[x])
  if(x == 1) alldat <- out
  if(x > 1) alldat <- rbind(alldat, out)

}

alldat$prop <- alldat$points/alldat$total
fb_pairs <- alldat
#this shows the proportion of time that pairs of upstream/downstream sensors behave according to the hypothesis of wetting up and drying down
hist(alldat$prop)
```
```{r looping-ZZ}
#equivalent to hush 2 from earlier,
#make a new input for each watershed chunk
input <- rbind(bind23, bind24) %>%
  filter(wshed == "ZZ", mins %in% c(0, 30)) %>%
  select(datetime, binary, ID) %>%
  mutate(ID = paste0("r_",ID)) %>% 
  pivot_wider(names_from = ID, values_from = binary)
#now make loop to loop through all pairs of sensors
routes <- read_csv("zz_flowrouting.csv") %>% drop_na() %>% 
  mutate(up = paste0("r_",up),
         down = paste0("r_",down))

for(x in 1:length(routes$up)){
  
  out <- calc_support(routes$up[x], routes$down[x])
  if(x == 1) alldat <- out
  if(x > 1) alldat <- rbind(alldat, out)

}

alldat$prop <- alldat$points/alldat$total
zz_pairs <- alldat
#this shows the proportion of time that pairs of upstream/downstream sensors behave according to the hypothesis of wetting up and drying down
hist(alldat$prop)
```
##looping by drainage area UNFINISHED
```{r create-3m-network}
streams <- "./HB/1m hydro enforced DEM/dem3m_streams.tif"
wbt_extract_streams(flow_accum = flowacc_output,
                    output = streams,
                    threshold = 500)
plot(rast(streams))
#w3 zoom
ybounds <- c(4870350,4871350)
xbounds <- c(281350, 282150)
plot(rast(streams), xlim = xbounds, ylim = ybounds)
points(lcc)
#zz () zoom
ybounds <- c(4866400,4867500)
xbounds <- c(277200, 277650)
```

```{r extract-drainage-area-W3}
#flow accumulation/upslope drainage area at 3 m resolution calculated earlier in markdown
#flowacc_output <- "./HB/1m hydro enforced DEM/dem3m_flowacc.tif"

#calculate for W3
locs <- data_24 %>% 
  filter(wshed == "W3") %>% 
  select(number, lat, long) %>% 
  rename("ID" = number) %>% 
  unique()
#convert STIC data to a SpatVector data format
locs_shape <- vect(locs, 
                   geom=c("long", "lat"), 
                   crs = "+proj=longlat +datum=WGS84")
plot(locs_shape)
#reproject coordinates from WGS84 to NAD83 19N, which is the projection of raster
lcc <- terra::project(locs_shape, crs(rast(flowacc_output)))

W3_uaa_ex <- extract(rast(flowacc_output), lcc)

#make list that makes pairs of sites based on topography
```
```{rextract-drainage-area-FB}
#calculate for FB
locs <- data_24 %>% 
  filter(wshed == "FB") %>% 
  select(number, lat, long) %>% 
  rename("ID" = number) %>% 
  unique()
#convert STIC data to a SpatVector data format
locs_shape <- vect(locs, 
                   geom=c("long", "lat"), 
                   crs = "+proj=longlat +datum=WGS84")
plot(locs_shape)
#reproject coordinates from WGS84 to NAD83 19N, which is the projection of raster
lcc <- terra::project(locs_shape, crs(rast(flowacc_output)))

#before extracting, I should snap points to stream network based on this resolution perhaps... ugh

FB_uaa_ex <- extract(rast(flowacc_output), lcc)

```

##looping by local persistency
```{r looping-W3}
#make list that make pairs of sites based on local persistency
routes <- pks_w3 %>% 
  arrange(desc(pk)) %>% 
  mutate(down = lag(ID)) %>% 
  rename("up" = ID) %>% drop_na() %>% 
  select(up, down)

input <- rbind(bind23, bind24) %>%
  filter(wshed == "W3", mins %in% c(0, 30)) %>%
  select(datetime, binary, ID) %>%
  mutate(ID = paste0("r_",ID)) %>% 
  pivot_wider(names_from = ID, values_from = binary)
#now make loop to loop through all pairs of sensors

for(x in 1:length(routes$up)){
  up <- paste0("r_",routes$up[x])
  down <- paste0("r_",routes$down[x])
  
  out <- calc_support(up, down)
  if(x == 1) alldat <- out
  if(x > 1) alldat <- rbind(alldat, out)

}

alldat$prop <- alldat$points/alldat$total
w3_pairs_pk <- alldat
#this shows the proportion of time that pairs of upstream/downstream sensors behave according to the hypothesis of wetting up and drying down
hist(w3_pairs_pk$prop)
hist(w3_pairs$prop)

```
```{r looping-FB}
#make list that make pairs of sites based on local persistency
routes <- pks_w3 %>% 
  arrange(desc(pk)) %>% 
  mutate(down = lag(ID)) %>% 
  rename("up" = ID) %>% drop_na() %>% 
  select(up, down)

input <- rbind(bind23, bind24) %>%
  filter(wshed == "W3", mins %in% c(0, 30)) %>%
  select(datetime, binary, ID) %>%
  mutate(ID = paste0("r_",ID)) %>% 
  pivot_wider(names_from = ID, values_from = binary)
#now make loop to loop through all pairs of sensors

for(x in 1:length(routes$up)){
  up <- paste0("r_",routes$up[x])
  down <- paste0("r_",routes$down[x])
  
  out <- calc_support(up, down)
  if(x == 1) alldat <- out
  if(x > 1) alldat <- rbind(alldat, out)

}

alldat$prop <- alldat$points/alldat$total
w3_pairs_pk <- alldat
#this shows the proportion of time that pairs of upstream/downstream sensors behave according to the hypothesis of wetting up and drying down
hist(w3_pairs_pk$prop)
hist(w3_pairs$prop)

pks_fb
pks_zz
```
##looping by dof
Test individual tribs, and the whole network
```{r}
dof_w3
dof_fb
dof_zz
```

Try for a sequence of 3 times- also shows that this systematic wetting is very common
```{r window3}
calc_support <- function(up, down){
mod3 <- drop_na(mod2[,-1]) %>% select(all_of(up),all_of(down))
no_dupes <- mod3 %>%
  filter(row_number() == 1 | !apply(. == lag(.), 1, all))
#make it so that there cannot be a sequence without change

# Define window size
window_size <- 3

# Create sliding windows
windows <- rollapply(
  no_dupes,
  width = window_size,
  by.column = FALSE,
  FUN = function(x) paste(as.vector(t(x)), collapse = "")
)

# Count and sort sequences
sequence_counts <- table(windows)
sorted_counts <- sort(sequence_counts, decreasing = TRUE)

# Display all sequences and their frequencies
sequence_df <- as.data.frame(sorted_counts, stringsAsFactors = FALSE)
colnames(sequence_df) <- c("Sequence", "Frequency")
#View(sequence_df)

total <- sum(sequence_df$Frequency)
#write some way to score the sequence_df
#award one point for one of these configs:

supports <- c("000111", "110100", "011101", "110111", "000100")
#subset from the 16 possibilities, except it is fewer because
#0000, 1111, 0101, 1010 are removed...

sub <- filter(sequence_df, Sequence %in% supports)
points <- sum(sub$Frequency)

#create output with the total and the sub, also the two input locations
output <- data.frame(up, down, points, total)
return(output)
}

calc_support("r_22", "r_23")
```

#final plot
```{r}
#boxplots or distributions of the percentage of state changes that follow some system, different colors/boxes for each scheme or system, and x axis is the number of sensors.

#facet for each watershed
```

