---
title: "Test Frameworks"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

9/8/24
Test different theoretical frameworks using my data.
```{r reading-in-STIC-obs}
#loading packages
library(pacman)
p_load(tidyverse, terra, tidyterra, whitebox)

#reading in final format data for summer 23
data_23 <- read_csv("./DataForMary/HB_stic.csv")
#reading in final format data for summer 24
data_24 <- read_csv("./summer2024/STICS2024.csv")
```
9/10/24
Make figures showing the full period of record
```{r full-record-w3-plot}
binary <- c("#DB995A",
            "#586BA4"
  )

data_23$mins <- minute(data_23$datetime)
data_24$mins <- minute(data_24$datetime)

head(filter(data_23, wshed == "W3", deployment == 1))
ggplot()+
  geom_tile(data = filter(data_23, wshed == "W3", mins %in% c(0, 30)),
            aes(x = datetime, y = ID, fill = wetdry))+
  geom_tile(data = filter(data_24, wshed == "W3", mins %in% c(0, 30)),
            aes(x = datetime, y = number, fill = wetdry))+
  #facet_grid(~deployment, scales = "free") + 
  scale_fill_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  labs(title = "Streamflow permanence in W3",
       x = "")+
  theme_classic()
```

FB
```{r full-record-FB-plot}

head(filter(data_24, wshed == "FB", sensor == 21736589))

ggplot()+
  geom_tile(data = filter(data_23, wshed == "FB", mins %in% c(0, 30)),
            aes(x = datetime, y = ID, fill = wetdry))+
  geom_tile(data = filter(data_24, wshed == "FB", mins %in% c(0, 30)),
            aes(x = datetime, y = number, fill = wetdry))+
  #facet_grid(~deployment, scales = "free") + 
  scale_fill_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  labs(title = "Streamflow permanence in FB",
       x = "")+
  theme_classic()
```
ZZ
```{r full-record-zz-plot}
ggplot()+
  geom_tile(data = filter(data_23, wshed == "ZZ", mins %in% c(0, 30)),
            aes(x = datetime, y = ID, fill = wetdry))+
  geom_tile(data = filter(data_24, wshed == "ZZ", mins %in% c(0, 30)),
            aes(x = datetime, y = number, fill = wetdry))+
  #facet_grid(~deployment, scales = "free") + 
  scale_fill_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  labs(title = "Streamflow permanence in ZZ",
       x = "")+
  theme_classic()
```

Start with Carrie's model- how well does it capture the dynamics that I observed?
```{r}
#read in discharge from W3-- input to Carrie's model, discharge in L/s
#q <- read_csv("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-hbr.1.17&entityid=efc477b3ef1bb3dd8b9355c9115cd849")
#write.csv(q, "HB_5minQ.csv")
q <- read_csv("HB_5minQ.csv")
#input discharge needs to be in mm/day?
#reference to understand difference between daily mean and instantaneous streamflow:
#https://hydrofunctions.readthedocs.io/en/master/notebooks/DailyMean_vs_Instant.html

#creating minute column, used to filter out higher temporal resolution measurements for plotting
data_23$mins <- minute(data_23$datetime)
data_24$mins <- minute(data_24$datetime)

#find the range of dates that I need discharge for
start <- min(data_23$datetime)
stop <- max(data_23$datetime)

#filtering discharge down to the range of dates
q_23 <- q %>% 
  filter(DATETIME > start & DATETIME < stop) %>% 
  #convert to mm/day.
  #converting instantaneous streamflow to mm/day by taking measurement, and scaling   it up as if that was the discharge for the whole day. It is not, it is just at that   moment, but should fix any units/order of magnitude issues
  mutate("Q_mm_day" = Discharge_ls * 0.001 * 86400 / 420000 * 1000) 
q_23$mins <- minute(q_23$DATETIME)

#removing times that are not coincident with STIC observations
q_23_f <- filter(q_23, mins %in% c(0, 30))

ggplot(q_23_f, aes(x  = DATETIME, y = Q_mm_day))+
  geom_line()+
  labs(title = "Discharge from W3, July to Nov 2023",
       x = "",
       y = "Instantaneous Q (mm/day)")+
  theme_classic()

```
  
```{r}
#calculate then extract the TWI at each of the sensor locations. May be tricky to make sure that they line up with flowlines, or places with greatest drainage area.
twi3 <- "./w3_dems/w3_dem_twi.tif"
#twi calculated in script topmodel_fromscratch_2_23_23.Rmd
twi3 <- rast(twi3)
plot(twi3)

#plot locations of sensors
locs <- data_23 %>% 
  filter(wshed == "W3") %>% 
  select(ID, lat, long) %>% 
  unique()

locs_shape <- vect(locs, 
                   geom=c("long", "lat"), 
                   crs = "+proj=longlat +datum=WGS84")
lcc <- terra::project(locs_shape,crs(twi3))

#extract twi values using terra::extract
twi_ex <- extract(twi3, lcc)

#these point locations are not manually corrected.
#in next chunk, calculate the percent chance that each spot is flowing based off of an input discharge
```

```{r}
#chunk that is actually running the model

#function to calculate probability of flow raster
willit <- function(input_logtwi, inputQ){
  #b0, or intercept from Kevin's email from Carrie, might need to redo regression
  b0 <- -35.43
  #all ofther coefs from Jensen et al. 2018
  twi_coef <- 15.57
  flow_coef <- 0.12

  b1x1 <- flow_coef * inputQ
  b2x2 <- twi_coef * input_logtwi

  #logistic regression from Jensen et al. 2018
  p <- exp(b0 + b1x1 + b2x2)/(1 + exp(b0 + b1x1 + b2x2))
  return(p)
}

test <- willit(log(twi3), 1)
plot(test)
#after running, threshold by some probability of flowing
#loop through the input dataframe of discharge, once for each sensor. make an indexed array perhaps?

test <- willit(twi_ex$w3_dem_twi, q_23_f$Q_mm_day)

#unmodified df to store output of for loop
mod <- q_23_f
#loop through discharge record for each STIC location
for(i in 1:length(twi_ex$ID)){
  mod$ID <- twi_ex$ID[i]
  mod$percent_flowing <- willit(log(twi_ex$w3_dem_twi[i]), mod$Q_mm_day)
  
  
  if(i == 1) final <- mod
  if(i > 1) final <- rbind(final, mod)

}

#thresholding resulting percent chances to get a binary of flowing/not flowing
#using three thresholds reported in Carrie's paper
final$per_90 <- 0
final$per_90[final$percent_flowing >= 90] <- 1

final$per_75 <- 0
final$per_75[final$percent_flowing >= 75] <- 1

final$per_50 <- 0
final$per_50[final$percent_flowing >= 50] <- 1
#then compare prediction versus actual
w3_23 <- filter(data_23, wshed == "W3") %>% 
  rename("DATETIME" = datetime)
#make a binary wet versus dry column
w3_23$binary <- 1
w3_23$binary[w3_23$wetdry == "dry"] <- 0

#join the two tables
forp <- left_join(w3_23, final, by = c("DATETIME", "ID"))
```

```{r}
#plot to compare observed versus predicted at all sensors
#hard to do for binary data, instead maybe calculate the percentage of time that it is correct?
#compare binary column to 3 different percent chance of flow columns
length(which(forp$binary == forp$per_90))/length(forp$DATETIME)
IDs <- unique(forp$ID)

for(i in 1:length(IDs)){
  inter <- filter(forp, ID == IDs[i])
  result <- length(which(inter$binary == inter$per_90))/length(inter$DATETIME)
  mod <- data.frame("ID" = IDs[i],
                    "percent_agree" = result)
  
  if(i == 1) final <- mod
  if(i > 1) final <- rbind(final, mod)

}

#plot through space
#Make a simple map for each watershed to serve as the template 
sheds <- vect('./HB/hbef_wsheds')
plot(sheds)
#method to subset shapefiles- use base r ways to subset
w3 <- sheds[2,]
plot(w3)

#read in shapefiles for each of the streams
w3_stream <- vect("./HB/hbstream/hb42_master_startend.shp")
w3_stream_wgs <- project(w3_stream, "+proj=longlat +datum=WGS84")
data_w3 <- unique(w3_23 %>% 
  dplyr::select(ID, lat, long)) %>% 
  left_join(final, by = "ID")

points_w3 <- vect(data_w3, geom=c("long", "lat"), crs = "+proj=longlat +datum=WGS84")

#create simple table that contains labels for points
# simple_table_w3 <- fb_n %>% 
#   select(number, sensor, lat, long) %>% 
#   unique() %>% 
#   mutate("status" = "Good (23)")
# simple_table_fb <- simple_table_fb[order(simple_table_fb$number),]


ggplot()+
  geom_spatvector(data = w3_stream_wgs, color = "grey", lwd = 1.5)+
  geom_spatvector(data = points_w3, aes(color = percent_agree), size = 3)+#aes(color = percent_flowing), size = 2)+
  #geom_text_repel(data = simple_table, aes(x = long, y = lat, label = number))+
  theme_void()+
  labs(title = "Agreement with Carrie's model")+
  theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))



```

```{r}
#run Carrie's model again on a courser twi dataset
#instead of using 10m dem on HB database, use coarsened 1m dem
#aggregate function, by factor of 10- 1 m resolution to 10 m res.
#tried just aggregating twi raster, but it looks funny
twi3_c <- aggregate(twi3, 10)
#should aggregate dem, then do all of the transformations to it
#read in 1 m dem
dem <- "./HB/1m hydro enforced DEM/dem1m.tif"
m1 <- rast(dem)
m10 <- aggregate(m1, 10)
plot(m10, xlim = c(281400, 282000),
     ylim = c(4870600, 4871200))
#first crop and mask to W3 shape
sheds <- vect('./HB/hbef_wsheds')
w3 <- sheds[2,]
dem_crop <- terra::crop(m10, w3)
dem_mask <- terra::mask(dem_crop, w3)
plot(dem_mask)
#save raster, because whitebox wants it is a files location instead of an object in R
#writeRaster(dem_mask, "./w3_dems/hbef_10mdem/10mdem_crop.tif")

cropped <- "./w3_dems/hbef_10mdem/10mdem_crop.tif"
twi <- terra::rast(cropped)
twi_crop <- terra::crop(twi, w3)
plot(twi_crop)

breach_output <- "./w3_dems/hbef_10mdem/10m_dem_breached.tif"
wbt_breach_depressions_least_cost(
  dem = cropped,
  output = breach_output,
  dist = 5,
  fill = TRUE)

fill_output <- "./w3_dems/hbef_10mdem/10m_dem_filled.tif"
wbt_fill_depressions_wang_and_liu(
  dem = breach_output,
  output = fill_output
)

flowacc_output <- "./w3_dems/hbef_10mdem/10m_dem_flowacc.tif"
wbt_d_inf_flow_accumulation(input = fill_output,
                            output = flowacc_output,
                            out_type = "Specific Contributing Area")

slope_output <- "./w3_dems/hbef_10mdem/10m_dem_slope.tif"
wbt_slope(dem = fill_output,
          output = slope_output,
          units = "degrees")

twi_output <- "./w3_dems/hbef_10mdem/10m_dem_twi.tif"
wbt_wetness_index(sca = flowacc_output, #flow accumulation
                  slope = slope_output,
                  output = twi_output)

twi <- terra::rast(twi_output)
twi_crop <- terra::crop(twi, w3)
plot(twi_crop)
# 9/16/24
#There is something wrong with the 10m dem that I have. Will try to download it from data repo again. 
#Reached out to Kevin and JP, the 10m dem on the repo is bad. instead use corsened 1 m lidar
```

```{r}
#re-run Carrie's model on the coarser DEM, and compare to my observations
#extract values of twi at sensor locations
```

```{r}
#coarsened DEM is not working, and I am going to test different scenarios anyway, so having it in the framework of a function will behoove me
#writing function form of Carrie's model
#inputs
#willit function already defined
willit <- function(input_logtwi, inputQ){
  #b0, or intercept from Kevin's email from Carrie, might need to redo regression
  b0 <- -35.43
  #all ofther coefs from Jensen et al. 2018
  twi_coef <- 15.57
  flow_coef <- 0.12

  b1x1 <- flow_coef * inputQ
  b2x2 <- twi_coef * input_logtwi

  #logistic regression from Jensen et al. 2018
  p <- exp(b0 + b1x1 + b2x2)/(1 + exp(b0 + b1x1 + b2x2))
  return(p)
}
#discharge is the next input

test <- willit(log(twi3), 1)
plot(test)

apply_regression <- function(inputQ, inputTWI, observations){
#unmodified df to store output of for loop
  mod <- inputQ
#loop through discharge record for each STIC location
  for(i in 1:length(inputTWI$ID)){
      mod$ID <- inputTWI$ID[i]
      mod$percent_flowing <- willit(log(inputTWI[i,2]), mod$Q_mm_day)
  
  
    if(i == 1) final <- mod
    if(i > 1) final <- rbind(final, mod)

  }
  #threshold resulting percent chances to get a binary of flowing/not flowing
  #using three thresholds reported in Carrie's paper
  final$per_90 <- 0
  final$per_90[final$percent_flowing >= 90] <- 1

  final$per_75 <- 0
  final$per_75[final$percent_flowing >= 75] <- 1

  final$per_50 <- 0
  final$per_50[final$percent_flowing >= 50] <- 1
  #then compare prediction versus actual
  w3_23 <- filter(observations, wshed == "W3") %>% 
    rename("DATETIME" = datetime)
  #make a binary wet versus dry column
  w3_23$binary <- 1
  w3_23$binary[w3_23$wetdry == "dry"] <- 0

  #join the two tables
  #forp is output that contains everything
  forp <- left_join(w3_23, final, by = c("DATETIME", "ID"))
  IDs <- unique(forp$ID)

  for(i in 1:length(IDs)){
  inter <- filter(forp, ID == IDs[i])
  result <- length(which(inter$binary == inter$per_90))/length(inter$DATETIME)
  mod <- data.frame("ID" = IDs[i],
                    "percent_agree" = result)
  
  if(i == 1) final <- mod
  if(i > 1) final <- rbind(final, mod)

  }
  #final or data_w3 contains summarized values
  #data_w3 is final output
  unique(w3_23 %>% 
  dplyr::select(ID, lat, long)) %>% 
  left_join(final, by = "ID")
}

applied <- apply_regression(inputQ = q_23_f,
                            inputTWI = twi_ex,
                            observations = data_23)
points_w3 <- vect(applied, geom=c("long", "lat"), crs = "+proj=longlat +datum=WGS84")
ggplot()+
  geom_spatvector(data = w3_stream_wgs, color = "grey", lwd = 1.5)+
  geom_spatvector(data = points_w3, aes(color = percent_agree), size = 3)+#aes(color = percent_flowing), size = 2)+
  #geom_text_repel(data = simple_table, aes(x = long, y = lat, label = number))+
  theme_void()+
  labs(title = "Agreement with Carrie's model")+
  theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))

```

```{r}

twi_ex2 <- extract(twi_crop, lcc)

applied <- apply_regression(inputQ = q_23_f,
                            inputTWI = twi_ex2,
                            observations = data_23)

points_w3 <- vect(applied, geom=c("long", "lat"), crs = "+proj=longlat +datum=WGS84")

ggplot()+
  geom_spatvector(data = w3_stream_wgs, color = "grey", lwd = 1.5)+
  geom_spatvector(data = points_w3, aes(color = percent_agree), size = 3)+#aes(color = percent_flowing), size = 2)+
  #geom_text_repel(data = simple_table, aes(x = long, y = lat, label = number))+
  theme_void()+
  labs(title = "Agreement with Carrie's model")+
  theme(plot.margin=grid::unit(c(0,0,0,0), "mm"))
```

9/24/24
Figure out why the values from the normal twi raster appear to be the same probability as those from the 10 m coarsened DEM. OR make sure that points align with where the twi raster thinks that the stream is
```{r}

```


```{r}
#under what wetness conditions does Carrie's model agree with my observations the most?
#where and when does the model agree the least?
#where does it do the worst and the best?
```

