---
title: "W3_network_STIC"
author: "John Morgan"
date: "2023-11-02"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r}
#setup
library(pacman)
p_load(tidyverse, raster, rgdal, sp, mapview,
       rgeos, spdplyr, tmap, stars, STICr,
       lubridate, gganimate, animation, patchwork, ggrepel)

```

```{r}
#analysis of W1 and W2 stic sensors
deploy <- read.csv("./Fieldwork_formatted_summer23/All_deployments.csv")
head(deploy)
w3 <- filter(deploy, wshed == "W3", deployment == 1)
w3_n <- na.omit(w3)
w3_n$start <- mdy_hm(w3_n$start)
w3_n$end <- mdy_hm(w3_n$end)
head(w3_n)

#folder called W3loggers_7_18_23, W3loggers_9_19_23
#went through folders, found duplicates and removed them
files <- list.files("./W3loggers_7_18_23", pattern = ".csv")
files
test <- read.csv(paste0("./W3loggers_7_18_23/", files[1]), skip = 1)
test$Datetime <- mdy_hms(test$Date.Time..GMT.04.00)
plot(test$Datetime, test$Intensity..lum.ft...LGR.S.N..20011654..SEN.S.N..20011654.)

#calibration curves
cal.list2 <- list.files("./CalibratingConductivity_9_20_23", pattern = ".csv")
cal.list <- list.files("./CalibratingConductivity_9_19_23", pattern = ".csv")
cal1 <- read.csv(paste0("./CalibratingConductivity_9_19_23/", cal.list[2]), skip = 1)
cal1$Datetime <- mdy_hms(cal1$Date.Time..GMT.04.00)
plot(cal1$Datetime, cal1$Intensity..lum.ft...LGR.S.N..20011677..SEN.S.N..20011677.)

#for now maybe just use absolute method
chosen <- paste0("./W3loggers_7_18_23/", files[1])
sensor_num <- substr(chosen, 21, 28)
#subset deployment information
deployment_info <- filter(w3_n, sensor == sensor_num)

data <- tidy_hobo_data(chosen)
wet <- classify_wetdry(data, classify_var = "condUncal", method = "absolute", threshold = 10)
#remove dates before and after start and end date of deployment
wet_filt <- filter(wet, datetime >= deployment_info$start) %>% 
  filter(datetime <= deployment_info$end)

ggplot(wet_filt)+
  geom_point(aes(x = datetime, y = tempC, color = wetdry))+
  theme_classic()

#It should be much better if I can develop a method of filtering flowing and not flowing based on diurnal patterns as well
```

Read in data for all locations using for loop
12/17/23- successfully made more flexible function, produces error message if sensor data (.csv) is missing from the folder containing the data for that deployment.
```{r}

#inputs: folder, ws, deployment
read_deployment <- function(folder, wshed1, deployment1){
#file location
# folder = "./HBLoggers_11_14_23/"
# wshed1 = "W3"
# deployment1 = 3
# i = 1
files <- list.files(folder, pattern = ".csv")
#deployment info
deploy <- read.csv("./Fieldwork_formatted_summer23/All_deployments.csv")
#filter values must have different names than colnames
w3 <- filter(deploy, wshed == wshed1 & deployment == deployment1)
w3_n <- na.omit(w3)
w3_n$start <- mdy_hm(w3_n$start)
w3_n$end <- mdy_hm(w3_n$end)

sensor_ids <- as.character(w3_n$sensor)
sensor_num <- (substr(files, 1, 8))

# r <- c(sensor_ids, sensor_num)
# r
# length(unique(r))

for(i in 1:length(sensor_ids)){
  chosen <- paste0(sensor_ids[i], ".csv") #line to add i
  tryCatch({
  path_to_chosen <- paste0(folder, chosen)
  data <- tidy_hobo_data(path_to_chosen)

  #subset deployment information
  deployment_info <- filter(w3_n, sensor == sensor_ids[i])

  wet <- classify_wetdry(data,
                         classify_var = "condUncal",
                         method = "absolute",
                         threshold = 10)
  #remove dates before and after start and end date of deployment
  wet_filt <- filter(wet, datetime > deployment_info$start) %>%
    filter(datetime < deployment_info$end) %>% 
    bind_cols(deployment_info)


  if(i == 1) alldat <- wet_filt
  if(i > 1) alldat <- rbind(alldat, wet_filt)
  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

#create new column that indicates if every sensor is deployed or not
alldat$all_deployed <- 0

alldat$all_deployed[alldat$datetime >= max(alldat$start) & alldat$datetime <= min(alldat$end)] <- 1

readout <- alldat %>% dplyr::select(-start, -end)

return(readout)
}

w3_1 <- read_deployment(folder = "./W3loggers_7_18_23/", 
                        wshed1 = "W3",
                        deployment1 = 1)
w3_2 <- read_deployment(folder = "./W3loggers_9_19_23/", 
                        wshed1 = "W3",
                        deployment1 = 2)
#got error, was due to spreadsheet having a duplicate record. For trouble shooting in the future- if a for loop fails, if i leave the index as the variable the loop is using, I can try to run each component of the loop on the one that failed.
w3_3 <- read_deployment(folder = "./HBLoggers_11_14_23/", 
                        wshed1 = "W3",
                        deployment1 = 3)

all_w3 <- rbind(w3_1, w3_2, w3_3)
all_w3$datetime <- with_tz(all_w3$datetime, "US/Eastern")


```

Reading in loggers in Falls Brook and Zig Zag
```{r}
fb_1 <- read_deployment(folder = "./FBloggers_7_19_23/", 
                        wshed1 = "FB",
                        deployment1 = 1)
fb_2 <- read_deployment(folder = "./FBloggers_9_20_23/", 
                        wshed1 = "FB",
                        deployment1 = 2)
fb_3 <- read_deployment(folder = "./HBLoggers_11_14_23/", 
                        wshed1 = "FB",
                        deployment1 = 3)

all_fb <- rbind(fb_1, fb_2, fb_3)


zz_1 <- read_deployment(folder = "./ZZloggers_7_20_23/", 
                        wshed1 = "ZZ",
                        deployment1 = 1)
zz_2 <- read_deployment(folder = "./ZZloggers_9_21_23/", 
                        wshed1 = "ZZ",
                        deployment1 = 2)
zz_3 <- read_deployment(folder = "./HBLoggers_11_14_23/", 
                        wshed1 = "ZZ",
                        deployment1 = 3)

all_zz <- rbind(zz_1, zz_2, zz_3)

all_sheds <- rbind(all_w3, all_fb, all_zz)

#qlist[(which(qlist$Streamflow >= 30)),]
all_sheds[which.max(all_sheds$tempC),]

all_sheds2 <- all_sheds[-(which(all_sheds$sensor == 20011664)),]
all_sheds2[which.max(all_sheds2$tempC),]

#convert temperature to degreese celsius, read in as farenheit from hoboware
all_sheds2$tempC <- (all_sheds2$tempC - 32) * 5/9

#create spreadsheet containing all of the data to send to Danielle Hare
#write.csv(all_sheds2, "./DataForDanielle/HB_stic.csv")
#data <- read_csv("./DataForDanielle/HB_stic.csv")
```

How do we visualize this information?
```{r}
#watershed 3 shape
sheds <- readOGR(dsn='./HB/hbef_wsheds')
w3 <- sheds %>% filter(WS == "WS3")
stream <- st_read("./HB/hbstream/hb42_master_startend.shp")
w3_rast <- raster("./HB/hbstream/w3_5m.tif")
w3_rast2 <- projectRaster(w3_rast, crs = 4326)
test <- as.data.frame(w3_rast2, xy = TRUE) %>%
  na.omit()

all_flowing <- filter(all_w3, all_deployed == 1)

plot_test <- filter(all_w3, 
               datetime == "2023-07-03 16:10:00.00",
               wshed == "W3")

binary <- c("red",
            "blue"
  )

ggplot()+
  geom_tile(data=test, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = plot_test, aes(x = long, y = lat, color = wetdry), size = 2)+
  scale_color_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  geom_text(data = plot_test, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()

wettest <- filter(all_w3, datetime == "2023-07-03 16:10:00")

```


Make plots for the wettest time and the driest time in all 3 watersheds
```{r}
#make binary columns for wet and dry
all_w3$binary <- 1
all_w3$binary[all_w3$wetdry == "dry"] <- 0

spots_flowing <- all_w3 %>% 
  group_by(datetime) %>% 
  summarise("percent_flowing" = sum(binary)/length(binary))

#maximum percentage of sensors flowing is 100%
max(spots_flowing$percent_flowing)
#times when stream was at it's maximum extent
spots_flowing$datetime[spots_flowing$percent_flowing == max(spots_flowing$percent_flowing)]
#minimum extent times
min(spots_flowing$percent_flowing)

spots_flowing$datetime[spots_flowing$percent_flowing == min(spots_flowing$percent_flowing)]

#plots for the wettest times for each watershed
plot_test <- filter(all_w3, 
               datetime == "2023-07-03 15:20:00 EDT")

ggplot()+
  geom_tile(data=test, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = plot_test, aes(x = long, y = lat, color = wetdry), size = 2)+
  scale_color_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  geom_text(data = plot_test, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  labs(title = "Wettest extent in W3")+
  coord_equal()
#plot of the driest extent in W3

plot_test <- filter(all_w3, 
               datetime == "2023-09-21 16:00:00 EDT")
ggplot()+
  geom_tile(data=test, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = plot_test, aes(x = long, y = lat, color = wetdry), size = 2)+
  scale_color_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  geom_text(data = plot_test, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  labs(title = "Driest extent in W3")+
  coord_equal()
```

instead of making plots for the wettest and driest times, make raster grid plots showing all times
```{r}
binary <- c("#754668",
            "#17BEBB"
  )

#remove measurements from first deployment that are not every 30 mins
plot_test <- filter(all_w3, deployment == 1)%>%
 slice(which(row_number() %% 3 == 0))
head(plot_test)

plot_test2 <- filter(all_zz, deployment != 1) #%>% rbind(plot_test)
dates <- unique(plot_test2$datetime)

spots_flowing <- plot_test2 %>% 
  group_by(datetime) %>% 
  summarise("percent_flowing" = sum(binary)/length(binary))

ggplot(plot_test2)+
  geom_tile(aes(x = datetime, y = ID, fill = wetdry))+
  #facet_grid(~deployment, scales = "free") + 
  scale_fill_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  labs(title = "Streamflow permanence in ZZ")+
  theme_classic()
#ways to make better
#order points by distance to outlet
#change colors
#add discharge and precipitation
```


Chunk not formatted yet- determine number of combinations of flowing points
```{r}
#find all unique combinations of wet and dry sensors
hush <- dplyr::select(data, datetime, wetdry_binary, ID) 
hush2 <- pivot_wider(hush, names_from = ID, values_from = wetdry_binary)

xy.list <- as.list(as.data.frame(t(hush2[,-1])))
length(xy.list)
length(unique(data$datetime))
#unique combinations of flow
length(unique(xy.list))
```


12/20/23
Make some quick figures for meeting with Danielle
```{r}
#watershed 3 shape

w3_rast <- raster("./HB/hbstream/w3_5m.tif")
fb_rast <- raster("./HB/hbstream/fb_5m.tif")
zz_rast <- raster("./HB/hbstream/zz_5m.tif")

w3_rast2 <- projectRaster(w3_rast, crs = 4326)
fb_rast2 <- projectRaster(fb_rast, crs = 4326)
zz_rast2 <- projectRaster(zz_rast, crs = 4326)

w3_df <- as.data.frame(w3_rast2, xy = TRUE) %>%
  na.omit()
fb_df <- as.data.frame(fb_rast2, xy = TRUE) %>%
  na.omit()
zz_df <- as.data.frame(zz_rast2, xy = TRUE) %>%
  na.omit()

data_w3 <- unique(all_w3 %>% 
  dplyr::select(ID, deployment, lat, long))
data_fb <- unique(all_fb %>% 
  dplyr::select(ID, deployment, lat, long))
data_zz <- unique(all_zz %>% 
  dplyr::select(ID, deployment, lat, long))


ggplot()+
  geom_tile(data = w3_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = data_w3, aes(x = long, y = lat, color = as.factor(deployment)), size = 2)+
  geom_text(data = data_w3, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()

ggplot()+
  geom_tile(data = fb_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = data_fb, aes(x = long, y = lat, color = as.factor(deployment)), size = 2)+
  geom_text(data = data_fb, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()

ggplot()+
  geom_tile(data = zz_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = data_zz, aes(x = long, y = lat, color = as.factor(deployment)), size = 2)+
  geom_text(data = data_zz, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()
```


Map of study watersheds for committee meeting
```{r}
sheds <- readOGR(dsn='./HB/hbef_wsheds')
w3 <- sheds %>% filter(WS == "WS3")
stream <- st_read("./HB/hbstream/hb42_master_startend.shp")
w3_rast <- raster("./HB/hbstream/w3_5m.tif")
w3_rast2 <- projectRaster(w3_rast, crs = 4326)
test <- as.data.frame(w3_rast2, xy = TRUE) %>%
  na.omit()

#study streams and whole network
w3_rast <- raster("./HB/hbstream/w3_5m.tif")
fb_rast <- raster("./HB/hbstream/fb_5m.tif")
zz_rast <- raster("./HB/hbstream/zz_5m.tif")
#use this layer, flow accumulation of 3500 m2 from 1m DEM of the whole valley
whole <- raster("./HB/hbstream/wholeValley1m_3500m2Thresh.tif")
test <- as.data.frame(whole, xy = TRUE) %>%
  na.omit()

stream <- st_read("./HB/hbstream/hb42_master_startend.shp")
fb <- st_read("./HB/hbstream/FB_subcatchment_flowlines.shp")
zz <- st_read("./HB/hbstream/ZZ_subcatchment_flowlines.shp")
#st_crs(stream)

st_crs(stream) <- 26919
st_crs(fb) <- 26919
st_crs(zz) <- 26919

data <- filter(all_w3, datetime == "2023-08-03 16:30:00")

binary <- c("red",
            "blue"
  )

ggplot()+
  geom_polygon(data = test, aes(x = x, y = y), colour = "black", fill = NA)
  #geom_text(data = data, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()
```


Animation for whole record and subset
```{r}
#make animation of august 6 to august 27th
data <- filter(all_w3, datetime >= "2023-08-06 00:00:00") %>% 
               filter(datetime <= "2023-08-20 23:00:00")

data <- filter(all_w3, datetime >= "2023-07-19 00:00:00") %>% 
               filter(datetime <= "2023-07-22 23:00:00")
x <- ggplot(data)+
  geom_tile(data=test, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(aes(x = long, y = lat, color = wetdry), size = 2)+
  scale_color_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+

   theme_classic()+ 
  transition_manual(datetime) +
  labs(title = "Date and Time: {current_frame}")



animate(x, 
        fps = 6,
        nframes = 600,         # fewer frames for simplification
        device = "png")

anim_save("ws3_aug_storm.gif", x,
          fps = 6,
          nframes = 300)

saveHTML(animate(x, 
                 fps = 6,
                 nframes = 600,         # fewer frames for simplification
                 device = "png"), 
         navigator = ani.options("nmax") <= 100 && ani.options("interval") >= 0.05,
         img.name = "tryingtoanimate.png", 
         htmlfile = "tryingtoanimate.html")
```

Flow routing
```{r}
routes <- read.csv("w3_flowrouting.csv")
```

```{r}
#find all unique combinations of wet and dry sensors
hush <- dplyr::select(data, datetime, wetdry_binary, ID) 
hush2 <- pivot_wider(hush, names_from = ID, values_from = wetdry_binary)

xy.list <- as.list(as.data.frame(t(hush2[,-1])))
length(xy.list)
length(unique(data$datetime))
#unique combinations of flow
length(unique(xy.list))



```

```{r}
#6/21/23 adding discharge and precip data
#read in data
q_raw <- read.csv("ws3_Q_6_21_2023.csv", skip = 2)
p_raw <- read.csv("ws3_P_6_21_2023.csv", skip = 3)
#remove dates outside of the extent of STIC deployment
q_raw$date.and.time <- mdy_hm(q_raw$date.and.time)
p_raw$date.time <- mdy_hm(p_raw$date.time)


q_date <- filter(q_raw, date.and.time >= "2023-06-06 14:00:00") %>% 
  filter(date.and.time <= "2023-06-14 11:00:00") %>% 
  rename("datetime" = "date.and.time")

p_date <- filter(p_raw, date.time >= "2023-06-06 14:00:00") %>% 
  filter(date.time <= "2023-06-14 11:00:00")
#convert inches to mm
p_date$mm <- p_date$inches * 25.4
p_date$day <- date(p_date$date.time)

p2 <- p_date %>% 
  group_by(day) %>% 
  summarise(daily_mmhr = sum(mm)/24)



ggplot(p2, aes(x = day, y = daily_mmhr))+
  geom_bar(stat = "identity")+
  theme_classic()+
  #transition_time(day) +
  labs(x = "", y = "Precip (mm/hr)", title = "Precipitation from June 6 to June 14")

ggplot(q_date, aes(x = datetime, y = mm.hr))+
  geom_line()+
  theme_classic()+
  labs(x = "Date", y = "Discharge (mm/hr)", title = "Discharge from June 6 to June 14")
q_date2 <- q_date
q_date2$datetime <- as.Date(q_date$datetime)


ggplot()+
  geom_bar(data = p2, aes(x = day, y = daily_mmhr), stat = "identity")+
  geom_line(data = q_date2, aes(x = datetime, y = mm.hr))+
  theme_classic()+
  #transition_time(day) +
  labs(x = "", y = "mm/hr", title = "Discharge and Precip from June 6 to June 14")
```

```{r}
#1/29/24
#Doing analysis from warix et al. 2021
#calculate seasonal flow permanence for each watershed
list <- c("W3", "FB", "ZZ")
out <- seq(1, 3, 1)

for(i in 1:length(list)){
one_shed <- filter(all_sheds2, 
               wshed == list[i])
#seasonal flow permanence of whole watershed for
perc_flow <- length(one_shed$wetdry[one_shed$wetdry == "wet"]) / length(one_shed$wetdry)
out[i] <- perc_flow
}

percent_seasonal_flow <- data.frame("shed" = list,
                                       "perc_flow" = out)
```

```{r}
#seasonal flow permanence at each point
#make binary columns for wet and dry
all_sheds2$binary <- 1
all_sheds2$binary[all_sheds2$wetdry == "dry"] <- 0


shed <- "W3"
#point_seasonal <- function(shed){
  one_shed <- filter(all_sheds2, 
               wshed == shed)
  IDs <- unique(one_shed$ID)

  w3_flowing <- one_shed %>% 
  group_by(ID)  %>% 
  reframe("percent_flowing" = sum(binary)/length(binary),
            "lat" = unique(lat),
            "long" = unique(long))
shed <- "FB"
#point_seasonal <- function(shed){
  one_shed <- filter(all_sheds2, 
               wshed == shed)
  IDs <- unique(one_shed$ID)

  fb_flowing <- one_shed %>% 
  group_by(ID)  %>% 
  reframe("percent_flowing" = sum(binary)/length(binary),
            "lat" = unique(lat),
            "long" = unique(long))
  
shed <- "ZZ"
#point_seasonal <- function(shed){
  one_shed <- filter(all_sheds2, 
               wshed == shed)
  IDs <- unique(one_shed$ID)

  zz_flowing <- one_shed %>% 
  group_by(ID)  %>% 
  reframe("percent_flowing" = sum(binary)/length(binary),
            "lat" = unique(lat),
            "long" = unique(long))
  
#watershed 3 shape

w3_rast <- raster("./HB/hbstream/w3_5m.tif")
fb_rast <- raster("./HB/hbstream/fb_5m.tif")
zz_rast <- raster("./HB/hbstream/zz_5m.tif")

w3_rast2 <- projectRaster(w3_rast, crs = 4326)
fb_rast2 <- projectRaster(fb_rast, crs = 4326)
zz_rast2 <- projectRaster(zz_rast, crs = 4326)

w3_df <- as.data.frame(w3_rast2, xy = TRUE) %>%
  na.omit()
fb_df <- as.data.frame(fb_rast2, xy = TRUE) %>%
  na.omit()
zz_df <- as.data.frame(zz_rast2, xy = TRUE) %>%
  na.omit()

data_w3 <- unique(all_w3 %>% 
  dplyr::select(ID, deployment, lat, long))
data_fb <- unique(all_fb %>% 
  dplyr::select(ID, deployment, lat, long))
data_zz <- unique(all_zz %>% 
  dplyr::select(ID, deployment, lat, long))


ggplot()+
  geom_tile(data = w3_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = w3_flowing, aes(x = long, y = lat, color = percent_flowing), size = 2)+
  geom_text_repel(data = w3_flowing, aes(x = long, y = lat,label = signif(percent_flowing, 2)))+
  scale_color_viridis_c()+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: W3")+
  coord_equal()

ggplot()+
  geom_tile(data = fb_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = fb_flowing, aes(x = long, y = lat, color = percent_flowing), size = 2)+
  geom_text_repel(data = fb_flowing, aes(x = long, y = lat,label = signif(percent_flowing, 2)))+
  scale_color_viridis_c()+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: FB")+
  coord_equal()


ggplot()+
  geom_tile(data = zz_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = zz_flowing, aes(x = long, y = lat, color = percent_flowing), size = 2)+
  geom_text_repel(data = zz_flowing, aes(x = long, y = lat,label = signif(percent_flowing, 2)))+
  scale_color_viridis_c()+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: ZZ")+
  coord_equal()


```

```{r}
#Now randomly subset the sensors by 10%, 50%, and 90% fewer sensors randomly. See how much the percentages change

#filter to just one watershed
boot <- function(shed, iterations, percent_retained){
  out <- seq(1, iterations, 1)

  one_shed <- filter(all_sheds2, 
                     wshed == shed)
  #for loop to bootstrap n = iterations times
  for(i in 1:iterations){
  
    IDs <- unique(one_shed$ID)
    set.seed(i)
    sampled <- sample(IDs, round(percent_retained * length(IDs)))
  
    pruned <- one_shed %>% 
      filter(ID %in% sampled)

    #seasonal flow permanence of whole watershed for
    perc_flow <- length(pruned$wetdry[pruned$wetdry == "wet"]) / length(pruned$wetdry)
    out[i] <- perc_flow
  }

  avg <- mean(out)
  sd <- sd(out)

final <- paste0(signif(avg, 2)," +/- ",signif(sd, 2))
}

w3_boot <- boot("W3", 100, 0.9)
fb_boot <- boot("FB", 100, 0.9)
zz_boot <- boot("ZZ", 100, 0.9)

w3_boot <- boot("W3", 100, 0.5)
fb_boot <- boot("FB", 100, 0.5)
zz_boot <- boot("ZZ", 100, 0.5)

w3_boot <- boot("W3", 100, 0.1)
fb_boot <- boot("FB", 100, 0.1)
zz_boot <- boot("ZZ", 100, 0.1)


list <- c("W3", "FB", "ZZ")
ninety <- data.frame("shed" = list, "perc_flow" = c(w3_boot, fb_boot, zz_boot))

#final calculation should be difference between the actual and the randomly sampled/reduced
```

```{r}
boot2 <- function(shed, iterations, percent_retained){
  out <- seq(1, iterations, 1)

  one_shed <- filter(all_sheds2, 
                     wshed == shed)
  #for loop to bootstrap n = iterations times
  for(i in 1:iterations){
  
    IDs <- unique(one_shed$ID)
    set.seed(i)
    sampled <- sample(IDs, round(percent_retained * length(IDs)))
  
    pruned <- one_shed %>% 
      filter(ID %in% sampled)

    #seasonal flow permanence of whole watershed for
    perc_flow <- length(pruned$wetdry[pruned$wetdry == "wet"]) / length(pruned$wetdry)
    out[i] <- perc_flow
  }

  avg <- mean(out)
  sd <- sd(out)

final <- paste0(signif(avg, 2)," +/- ",signif(sd, 2))
}

  

shed <- "ZZ"
#point_seasonal <- function(shed){
  one_shed <- filter(all_sheds2, 
               wshed == shed)
  IDs <- unique(one_shed$ID)
  
  sampled <- sample(IDs, round(0.5 * length(IDs)))


  zz_flowing <- one_shed %>% 
  filter(ID %in% sampled) %>% 
  group_by(ID)  %>% 
  reframe("percent_flowing" = sum(binary)/length(binary),
            "lat" = unique(lat),
            "long" = unique(long))
  
ggplot()+
  geom_tile(data = zz_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = zz_flowing, aes(x = long, y = lat, color = percent_flowing), size = 2)+
  geom_text_repel(data = zz_flowing, aes(x = long, y = lat,label = signif(percent_flowing, 2)))+
  scale_color_viridis_c()+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: ZZ, 50% of sensors")+
  coord_equal()
```

