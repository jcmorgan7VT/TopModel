---
title: "W3_network_STIC"
author: "John Morgan"
date: "2023-11-02"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r}
#setup
library(pacman)
p_load(tidyverse, sp, mapview,
       rgeos, spdplyr, tmap, stars, STICr,
       lubridate, gganimate, animation, patchwork, ggrepel, whitebox,
       terra)
install.packages("rgdal")
```


Read in data for all locations using for loop
12/17/23- successfully made more flexible function, produces error message if sensor data (.csv) is missing from the folder containing the data for that deployment.
```{r}

#inputs: folder, ws, deployment
read_deployment <- function(folder, wshed1, deployment1){
#file location
# folder = "./HBLoggers_11_14_23/"
# wshed1 = "W3"
# deployment1 = 3
# i = 1
files <- list.files(folder, pattern = ".csv")
#deployment info
deploy <- read.csv("./Fieldwork_formatted_summer23/All_deployments.csv")
#filter values must have different names than colnames
w3 <- filter(deploy, wshed == wshed1 & deployment == deployment1)
w3_n <- na.omit(w3)
w3_n$start <- mdy_hm(w3_n$start)
w3_n$end <- mdy_hm(w3_n$end)

sensor_ids <- as.character(w3_n$sensor)
sensor_num <- (substr(files, 1, 8))

# r <- c(sensor_ids, sensor_num)
# r
# length(unique(r))

for(i in 1:length(sensor_ids)){
  chosen <- paste0(sensor_ids[i], ".csv") #line to add i
  tryCatch({
  path_to_chosen <- paste0(folder, chosen)
  data <- tidy_hobo_data(path_to_chosen)

  #subset deployment information
  deployment_info <- filter(w3_n, sensor == sensor_ids[i])

  wet <- classify_wetdry(data,
                         classify_var = "condUncal",
                         method = "absolute",
                         threshold = 10)
  #remove dates before and after start and end date of deployment
  wet_filt <- filter(wet, datetime > deployment_info$start) %>%
    filter(datetime < deployment_info$end) %>% 
    bind_cols(deployment_info)


  if(i == 1) alldat <- wet_filt
  if(i > 1) alldat <- rbind(alldat, wet_filt)
  }, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})
}

#create new column that indicates if every sensor is deployed or not
alldat$all_deployed <- 0

alldat$all_deployed[alldat$datetime >= max(alldat$start) & alldat$datetime <= min(alldat$end)] <- 1

readout <- alldat %>% dplyr::select(-start, -end)

return(readout)
}

w3_1 <- read_deployment(folder = "./W3loggers_7_18_23/", 
                        wshed1 = "W3",
                        deployment1 = 1)
w3_2 <- read_deployment(folder = "./W3loggers_9_19_23/", 
                        wshed1 = "W3",
                        deployment1 = 2)
#got error, was due to spreadsheet having a duplicate record. For trouble shooting in the future- if a for loop fails, if i leave the index as the variable the loop is using, I can try to run each component of the loop on the one that failed.
w3_3 <- read_deployment(folder = "./HBLoggers_11_14_23/", 
                        wshed1 = "W3",
                        deployment1 = 3)

all_w3 <- rbind(w3_1, w3_2, w3_3)
all_w3$datetime <- with_tz(all_w3$datetime, "US/Eastern")


```

Reading in loggers in Falls Brook and Zig Zag
```{r}
fb_1 <- read_deployment(folder = "./FBloggers_7_19_23/", 
                        wshed1 = "FB",
                        deployment1 = 1)
fb_2 <- read_deployment(folder = "./FBloggers_9_20_23/", 
                        wshed1 = "FB",
                        deployment1 = 2)
fb_3 <- read_deployment(folder = "./HBLoggers_11_14_23/", 
                        wshed1 = "FB",
                        deployment1 = 3)

all_fb <- rbind(fb_1, fb_2, fb_3)


zz_1 <- read_deployment(folder = "./ZZloggers_7_20_23/", 
                        wshed1 = "ZZ",
                        deployment1 = 1)
zz_2 <- read_deployment(folder = "./ZZloggers_9_21_23/", 
                        wshed1 = "ZZ",
                        deployment1 = 2)
zz_3 <- read_deployment(folder = "./HBLoggers_11_14_23/", 
                        wshed1 = "ZZ",
                        deployment1 = 3)

all_zz <- rbind(zz_1, zz_2, zz_3)

all_sheds <- rbind(all_w3, all_fb, all_zz)

#qlist[(which(qlist$Streamflow >= 30)),]
all_sheds[which.max(all_sheds$tempC),]

all_sheds2 <- all_sheds[-(which(all_sheds$sensor == 20011664)),]
all_sheds2[which.max(all_sheds2$tempC),]

#convert temperature to degreese celsius, read in as farenheit from hoboware
all_sheds2$tempC <- (all_sheds2$tempC - 32) * 5/9

#create spreadsheet containing all of the data to send to Danielle Hare
#write.csv(all_sheds2, "./DataForDanielle/HB_stic.csv")
#data <- read_csv("./DataForDanielle/HB_stic.csv")
```

How do we visualize this information?
```{r}
#watershed 3 shape
sheds <- readOGR(dsn='./HB/hbef_wsheds')
w3 <- sheds %>% filter(WS == "WS3")
stream <- st_read("./HB/hbstream/hb42_master_startend.shp")
w3_rast <- raster("./HB/hbstream/w3_5m.tif")
w3_rast2 <- projectRaster(w3_rast, crs = 4326)
test <- as.data.frame(w3_rast2, xy = TRUE) %>%
  na.omit()

all_flowing <- filter(all_w3, all_deployed == 1)

plot_test <- filter(all_w3, 
               datetime == "2023-07-03 16:10:00.00",
               wshed == "W3")

binary <- c("red",
            "blue"
  )

ggplot()+
  geom_tile(data=test, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = plot_test, aes(x = long, y = lat, color = wetdry), size = 2)+
  scale_color_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  geom_text(data = plot_test, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()

wettest <- filter(all_w3, datetime == "2023-07-03 16:10:00")

```


Make plots for the wettest time and the driest time in all 3 watersheds
```{r}
#make binary columns for wet and dry
all_w3$binary <- 1
all_w3$binary[all_w3$wetdry == "dry"] <- 0

spots_flowing <- all_w3 %>% 
  group_by(datetime) %>% 
  summarise("percent_flowing" = sum(binary)/length(binary))

#maximum percentage of sensors flowing is 100%
max(spots_flowing$percent_flowing)
#times when stream was at it's maximum extent
spots_flowing$datetime[spots_flowing$percent_flowing == max(spots_flowing$percent_flowing)]
#minimum extent times
min(spots_flowing$percent_flowing)

spots_flowing$datetime[spots_flowing$percent_flowing == min(spots_flowing$percent_flowing)]

#plots for the wettest times for each watershed
plot_test <- filter(all_w3, 
               datetime == "2023-07-03 15:20:00 EDT")

ggplot()+
  geom_tile(data=test, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = plot_test, aes(x = long, y = lat, color = wetdry), size = 2)+
  scale_color_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  geom_text(data = plot_test, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  labs(title = "Wettest extent in W3")+
  coord_equal()
#plot of the driest extent in W3

plot_test <- filter(all_w3, 
               datetime == "2023-09-21 16:00:00 EDT")
ggplot()+
  geom_tile(data=test, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = plot_test, aes(x = long, y = lat, color = wetdry), size = 2)+
  scale_color_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  geom_text(data = plot_test, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  labs(title = "Driest extent in W3")+
  coord_equal()
```

instead of making plots for the wettest and driest times, make raster grid plots showing all times
```{r}
binary <- c("#754668",
            "#17BEBB"
  )

#remove measurements from first deployment that are not every 30 mins
plot_test <- filter(all_w3, deployment == 1)%>%
 slice(which(row_number() %% 3 == 0))
head(plot_test)

plot_test2 <- filter(all_zz, deployment != 1) #%>% rbind(plot_test)
dates <- unique(plot_test2$datetime)

spots_flowing <- plot_test2 %>% 
  group_by(datetime) %>% 
  summarise("percent_flowing" = sum(binary)/length(binary))

ggplot(plot_test2)+
  geom_tile(aes(x = datetime, y = ID, fill = wetdry))+
  #facet_grid(~deployment, scales = "free") + 
  scale_fill_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+
  labs(title = "Streamflow permanence in ZZ")+
  theme_classic()
#ways to make better
#order points by distance to outlet
#change colors
#add discharge and precipitation
```


Chunk not formatted yet- determine number of combinations of flowing points
```{r}
#find all unique combinations of wet and dry sensors
hush <- dplyr::select(data, datetime, wetdry_binary, ID) 
hush2 <- pivot_wider(hush, names_from = ID, values_from = wetdry_binary)

xy.list <- as.list(as.data.frame(t(hush2[,-1])))
length(xy.list)
length(unique(data$datetime))
#unique combinations of flow
length(unique(xy.list))
```


12/20/23
Make some quick figures for meeting with Danielle
```{r}
#watershed 3 shape

w3_rast <- raster("./HB/hbstream/w3_5m.tif")
fb_rast <- raster("./HB/hbstream/fb_5m.tif")
zz_rast <- raster("./HB/hbstream/zz_5m.tif")

w3_rast2 <- projectRaster(w3_rast, crs = 4326)
fb_rast2 <- projectRaster(fb_rast, crs = 4326)
zz_rast2 <- projectRaster(zz_rast, crs = 4326)

w3_df <- as.data.frame(w3_rast2, xy = TRUE) %>%
  na.omit()
fb_df <- as.data.frame(fb_rast2, xy = TRUE) %>%
  na.omit()
zz_df <- as.data.frame(zz_rast2, xy = TRUE) %>%
  na.omit()

data_w3 <- unique(all_w3 %>% 
  dplyr::select(ID, deployment, lat, long))
data_fb <- unique(all_fb %>% 
  dplyr::select(ID, deployment, lat, long))
data_zz <- unique(all_zz %>% 
  dplyr::select(ID, deployment, lat, long))


ggplot()+
  geom_tile(data = w3_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = data_w3, aes(x = long, y = lat, color = as.factor(deployment)), size = 2)+
  geom_text(data = data_w3, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()

ggplot()+
  geom_tile(data = fb_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = data_fb, aes(x = long, y = lat, color = as.factor(deployment)), size = 2)+
  geom_text(data = data_fb, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()

ggplot()+
  geom_tile(data = zz_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = data_zz, aes(x = long, y = lat, color = as.factor(deployment)), size = 2)+
  geom_text(data = data_zz, aes(x = long, y = lat,label = ID), hjust=-0.00025, vjust=0.00025)+
  theme_void()+
  coord_equal()
```


Map of study watersheds for committee meeting
```{r}
sheds <- readOGR(dsn='./HB/hbef_wsheds')
w3 <- sheds %>% filter(WS == "WS3")
stream <- st_read("./HB/hbstream/hb42_master_startend.shp")
w3_rast <- raster("./HB/hbstream/w3_5m.tif")
w3_rast2 <- projectRaster(w3_rast, crs = 4326)
test <- as.data.frame(w3_rast2, xy = TRUE) %>%
  na.omit()

#study streams and whole network
w3_rast <- raster("./HB/hbstream/w3_5m.tif")
fb_rast <- raster("./HB/hbstream/fb_5m.tif")
zz_rast <- raster("./HB/hbstream/zz_5m.tif")
#use this layer, flow accumulation of 3500 m2 from 1m DEM of the whole valley
whole <- raster("./HB/hbstream/wholeValley1m_3500m2Thresh.tif")
test <- as.data.frame(whole, xy = TRUE) %>%
  na.omit()

stream <- st_read("./HB/hbstream/hb42_master_startend.shp")
fb <- st_read("./HB/hbstream/FB_subcatchment_flowlines.shp")
zz <- st_read("./HB/hbstream/ZZ_subcatchment_flowlines.shp")
#st_crs(stream)

st_crs(stream) <- 26919
st_crs(fb) <- 26919
st_crs(zz) <- 26919

data <- filter(all_w3, datetime == "2023-08-03 16:30:00")

binary <- c("red",
            "blue"
  )

```


Animation for whole record and subset
```{r}
#make animation of august 6 to august 27th
data <- filter(all_w3, datetime >= "2023-08-06 00:00:00") %>% 
               filter(datetime <= "2023-08-20 23:00:00")

data <- filter(all_w3, datetime >= "2023-07-19 00:00:00") %>% 
               filter(datetime <= "2023-07-22 23:00:00")
x <- ggplot(data)+
  geom_tile(data=test, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(aes(x = long, y = lat, color = wetdry), size = 2)+
  scale_color_manual(drop = FALSE,
                     values = binary,
                    breaks = c("dry", "wet"),
                    labels = c("No flow", "flowing"),
                    name = ""
                    )+

   theme_classic()+ 
  transition_manual(datetime) +
  labs(title = "Date and Time: {current_frame}")



animate(x, 
        fps = 6,
        nframes = 600,         # fewer frames for simplification
        device = "png")

anim_save("ws3_aug_storm.gif", x,
          fps = 6,
          nframes = 300)

saveHTML(animate(x, 
                 fps = 6,
                 nframes = 600,         # fewer frames for simplification
                 device = "png"), 
         navigator = ani.options("nmax") <= 100 && ani.options("interval") >= 0.05,
         img.name = "tryingtoanimate.png", 
         htmlfile = "tryingtoanimate.html")
```

Flow routing
```{r}
routes <- read.csv("w3_flowrouting.csv")
```

```{r}
#find all unique combinations of wet and dry sensors
hush <- dplyr::select(data, datetime, wetdry_binary, ID) 
hush2 <- pivot_wider(hush, names_from = ID, values_from = wetdry_binary)

xy.list <- as.list(as.data.frame(t(hush2[,-1])))
length(xy.list)
length(unique(data$datetime))
#unique combinations of flow
length(unique(xy.list))



```

```{r}
#6/21/23 adding discharge and precip data
#read in data
q_raw <- read.csv("ws3_Q_6_21_2023.csv", skip = 2)
p_raw <- read.csv("ws3_P_6_21_2023.csv", skip = 3)
#remove dates outside of the extent of STIC deployment
q_raw$date.and.time <- mdy_hm(q_raw$date.and.time)
p_raw$date.time <- mdy_hm(p_raw$date.time)


q_date <- filter(q_raw, date.and.time >= "2023-06-06 14:00:00") %>% 
  filter(date.and.time <= "2023-06-14 11:00:00") %>% 
  rename("datetime" = "date.and.time")

p_date <- filter(p_raw, date.time >= "2023-06-06 14:00:00") %>% 
  filter(date.time <= "2023-06-14 11:00:00")
#convert inches to mm
p_date$mm <- p_date$inches * 25.4
p_date$day <- date(p_date$date.time)

p2 <- p_date %>% 
  group_by(day) %>% 
  summarise(daily_mmhr = sum(mm)/24)



ggplot(p2, aes(x = day, y = daily_mmhr))+
  geom_bar(stat = "identity")+
  theme_classic()+
  #transition_time(day) +
  labs(x = "", y = "Precip (mm/hr)", title = "Precipitation from June 6 to June 14")

ggplot(q_date, aes(x = datetime, y = mm.hr))+
  geom_line()+
  theme_classic()+
  labs(x = "Date", y = "Discharge (mm/hr)", title = "Discharge from June 6 to June 14")
q_date2 <- q_date
q_date2$datetime <- as.Date(q_date$datetime)


ggplot()+
  geom_bar(data = p2, aes(x = day, y = daily_mmhr), stat = "identity")+
  geom_line(data = q_date2, aes(x = datetime, y = mm.hr))+
  theme_classic()+
  #transition_time(day) +
  labs(x = "", y = "mm/hr", title = "Discharge and Precip from June 6 to June 14")
```

```{r}
#1/29/24
#Doing analysis from warix et al. 2021
#calculate seasonal flow permanence for each watershed
list <- c("W3", "FB", "ZZ")
out <- seq(1, 3, 1)

for(i in 1:length(list)){
one_shed <- filter(all_sheds2, 
               wshed == list[i])
#seasonal flow permanence of whole watershed for
perc_flow <- length(one_shed$wetdry[one_shed$wetdry == "wet"]) / length(one_shed$wetdry)
out[i] <- perc_flow
}

percent_seasonal_flow <- data.frame("shed" = list,
                                       "perc_flow" = out)
```

```{r}
#seasonal flow permanence at each point
#make binary columns for wet and dry
all_sheds2$binary <- 1
all_sheds2$binary[all_sheds2$wetdry == "dry"] <- 0


shed <- "W3"
#point_seasonal <- function(shed){
  one_shed <- filter(all_sheds2, 
               wshed == shed)
  IDs <- unique(one_shed$ID)

  w3_flowing <- one_shed %>% 
  group_by(ID)  %>% 
  reframe("percent_flowing" = sum(binary)/length(binary),
            "lat" = unique(lat),
            "long" = unique(long))
shed <- "FB"
#point_seasonal <- function(shed){
  one_shed <- filter(all_sheds2, 
               wshed == shed)
  IDs <- unique(one_shed$ID)

  fb_flowing <- one_shed %>% 
  group_by(ID)  %>% 
  reframe("percent_flowing" = sum(binary)/length(binary),
            "lat" = unique(lat),
            "long" = unique(long))
  
shed <- "ZZ"
#point_seasonal <- function(shed){
  one_shed <- filter(all_sheds2, 
               wshed == shed)
  IDs <- unique(one_shed$ID)

  zz_flowing <- one_shed %>% 
  group_by(ID)  %>% 
  reframe("percent_flowing" = sum(binary)/length(binary),
            "lat" = unique(lat),
            "long" = unique(long))
  
#watershed 3 shape

w3_rast <- raster("./HB/hbstream/w3_5m.tif")
fb_rast <- terra::rast("./HB/hbstream/fb_5m.tif")
zz_rast <- terra::rast("./HB/hbstream/zz_5m.tif")

#w3_rast2 <- projectRaster(w3_rast, crs = "4326")
#fb_rast2 <- projectRaster(fb_rast, crs = 4326)
#zz_rast2 <- projectRaster(zz_rast, crs = 4326)

w3_df <- as.data.frame(w3_rast, xy = TRUE) %>%
  na.omit()
fb_df <- as.data.frame(fb_rast, xy = TRUE) %>%
  na.omit()
zz_df <- as.data.frame(zz_rast, xy = TRUE) %>%
  na.omit()

data_w3 <- unique(all_w3 %>% 
  dplyr::select(ID, deployment, lat, long))
data_fb <- unique(all_fb %>% 
  dplyr::select(ID, deployment, lat, long))
data_zz <- unique(all_zz %>% 
  dplyr::select(ID, deployment, lat, long))


ggplot()+
  geom_tile(data = w3_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = w3_flowing, aes(x = long, y = lat, color = percent_flowing), size = 2)+
 # geom_text_repel(data = w3_flowing, aes(x = long, y = lat,label = signif(percent_flowing, 2)))+
  scale_colour_gradient(high = "darkslategray1", low = "darkslategray")+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: W3")+
  coord_equal()

ggplot()+
  geom_tile(data = fb_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = fb_flowing, aes(x = long, y = lat, color = percent_flowing), size = 2)+
  geom_text_repel(data = fb_flowing, aes(x = long, y = lat,label = signif(percent_flowing, 2)))+
  scale_colour_gradient(high = "darkslategray1", low = "darkslategray")+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: FB")+
  coord_equal()


ggplot()+
  geom_tile(data = zz_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = zz_flowing, aes(x = long, y = lat, color = percent_flowing), size = 2)+
  geom_text_repel(data = zz_flowing, aes(x = long, y = lat,label = signif(percent_flowing, 2)))+
  scale_colour_gradient(high = "darkslategray1", low = "darkslategray")+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: ZZ")+
  coord_equal()


```

```{r}
#Now randomly subset the sensors by 10%, 50%, and 90% fewer sensors randomly. See how much the percentages change

#filter to just one watershed
boot <- function(shed, iterations, percent_retained){
  out <- seq(1, iterations, 1)

  one_shed <- filter(all_sheds2, 
                     wshed == shed)
  #for loop to bootstrap n = iterations times
  for(i in 1:iterations){
  
    IDs <- unique(one_shed$ID)
    set.seed(i)
    sampled <- sample(IDs, round(percent_retained * length(IDs)))
  
    pruned <- one_shed %>% 
      filter(ID %in% sampled)

    #seasonal flow permanence of whole watershed for
    perc_flow <- length(pruned$wetdry[pruned$wetdry == "wet"]) / length(pruned$wetdry)
    out[i] <- perc_flow
  }

  avg <- mean(out)
  sd <- sd(out)

final <- paste0(signif(avg, 2)," +/- ",signif(sd, 2))
}

w3_boot <- boot("W3", 100, 0.9)
fb_boot <- boot("FB", 100, 0.9)
zz_boot <- boot("ZZ", 100, 0.9)

w3_boot <- boot("W3", 100, 0.5)
fb_boot <- boot("FB", 100, 0.5)
zz_boot <- boot("ZZ", 100, 0.5)

w3_boot <- boot("W3", 100, 0.1)
fb_boot <- boot("FB", 100, 0.1)
zz_boot <- boot("ZZ", 100, 0.1)


list <- c("W3", "FB", "ZZ")
ninety <- data.frame("shed" = list, "perc_flow" = c(w3_boot, fb_boot, zz_boot))

#final calculation should be difference between the actual and the randomly sampled/reduced
```

```{r}
boot2 <- function(shed, iterations, percent_retained){
  out <- seq(1, iterations, 1)

  one_shed <- filter(all_sheds2, 
                     wshed == shed)
  #for loop to bootstrap n = iterations times
  for(i in 1:iterations){
  
    IDs <- unique(one_shed$ID)
    set.seed(i)
    sampled <- sample(IDs, round(percent_retained * length(IDs)))
  
    pruned <- one_shed %>% 
      filter(ID %in% sampled)

    #seasonal flow permanence of whole watershed for
    perc_flow <- length(pruned$wetdry[pruned$wetdry == "wet"]) / length(pruned$wetdry)
    out[i] <- perc_flow
  }

  avg <- mean(out)
  sd <- sd(out)

final <- paste0(signif(avg, 2)," +/- ",signif(sd, 2))
}

  

shed <- "ZZ"
#point_seasonal <- function(shed){
  one_shed <- filter(all_sheds2, 
               wshed == shed)
  IDs <- unique(one_shed$ID)
  
  sampled <- sample(IDs, round(0.5 * length(IDs)))


  zz_flowing <- one_shed %>% 
  filter(ID %in% sampled) %>% 
  group_by(ID)  %>% 
  reframe("percent_flowing" = sum(binary)/length(binary),
            "lat" = unique(lat),
            "long" = unique(long))
  
ggplot()+
  geom_tile(data = zz_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = zz_flowing, aes(x = long, y = lat, color = -percent_flowing), size = 2)+
  geom_text_repel(data = zz_flowing, aes(x = long, y = lat,label = signif(percent_flowing, 2)))+
  #scale_color_viridis_c()+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: ZZ, 50% of sensors")+
  coord_equal()
```

From meeting 1/29/24- don't just subset sensors randomly, test different sampling schemes that someone might actually implement in a real study
```{r}

#plot to help me figure out where each sensor is
ggplot()+
  geom_tile(data = w3_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = w3_flowing, aes(x = long, y = lat, color = percent_flowing), size = 2)+
 geom_text_repel(data = w3_flowing, aes(x = long, y = lat,label = ID))+
  scale_colour_gradient(high = "darkslategray1", low = "darkslategray")+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: W3")+
  coord_equal()

#one sensor per tributary, located centrally
#remove sensors
subset <- c(3, 7, 13, 16, 20, 23, 27, 28, 29, 30, 10)
w3_flowing_subset <- filter(w3_flowing, ID %in% subset)

ggplot()+
  geom_tile(data = w3_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = w3_flowing_subset, aes(x = long, y = lat, color = percent_flowing), size = 2)+
 geom_text_repel(data = w3_flowing_subset, aes(x = long, y = lat,label = ID))+
  scale_colour_gradient(high = "darkslategray1", low = "darkslategray",
                        breaks = c(0.25, 0.5, 0.75, 1),
                        labels = c("0.25", "0.5", "0.75", "1"),
                        name = "% time flowing")+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: W3")+
  coord_equal()



one_shed <- filter(all_sheds2, 
               wshed == "W3",
               ID %in% subset)

length(one_shed$wetdry[one_shed$wetdry == "wet"]) / length(one_shed$wetdry)

mean(w3_flowing_subset$percent_flowing)

  
# Is averaging the flowing percentages the same as taking all otal times that something was flowing or not flowing and dividing it by the total number of times?
  # They are very slightly different- I am going to stick with the fully integrated idea

# Sensors at the beginning and end of tribs
subset <- c(1, 4, 5, 11, 14, 8, 15, 17, 18, 21, 22, 26, 24, 10, 29, 30)
one_shed <- filter(all_sheds2, 
               wshed == "W3",
               ID %in% subset)
w3_flowing_subset <- filter(w3_flowing, ID %in% subset)

ggplot()+
  geom_tile(data = w3_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = w3_flowing_subset, aes(x = long, y = lat, color = percent_flowing), size = 2)+
 geom_text_repel(data = w3_flowing_subset, aes(x = long, y = lat,label = ID))+
  scale_colour_gradient(high = "darkslategray1", low = "darkslategray",
                        breaks = c(0.25, 0.5, 0.75, 1),
                        labels = c("0.25", "0.5", "0.75", "1"),
                        name = "% time flowing")+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: W3")+
  coord_equal()
length(one_shed$wetdry[one_shed$wetdry == "wet"]) / length(one_shed$wetdry)

```

```{r}
# easiest to access tribs
subset <- c(31, 24, 22, 21, 15, 14, 1)
one_shed <- filter(all_sheds2, 
               wshed == "W3",
               ID %in% subset)
w3_flowing_subset <- filter(w3_flowing, ID %in% subset)

ggplot()+
  geom_tile(data = w3_df, aes(x=x, y=y), fill = "lightgrey")+
  geom_point(data = w3_flowing_subset, aes(x = long, y = lat, color = percent_flowing), size = 2)+
 geom_text_repel(data = w3_flowing_subset, aes(x = long, y = lat,label = ID))+
  scale_colour_gradient(high = "darkslategray1", low = "darkslategray",
                        limits = c(0,1),
                        breaks = c(0, 0.5, 1),
                        labels = c("0", "0.5", "1"),
                        name = "% time flowing")+
  theme_void()+
  labs(title = "Seasonal Flow Permanence: W3")+
  coord_equal()
length(one_shed$wetdry[one_shed$wetdry == "wet"]) / length(one_shed$wetdry)
```

Geospatial analysis for Hubbard Brook study catchments
```{r}
#make sure terra and whitebox tools are loaded packages
#pour point coords, easting then northing
w3_coords <- c(281543.36, 4870433.54)
fb_coords <- c(280406.59, 4869122.57)
zz_coords <- c(277280.37, 4867436.63)

#provide path to flow direction raster for the whole valley
d8 <- "./HB/hbef_wsheds/5mhydro_6_10_23/D8pointer.tif"

#create pour point shapefile
#make dataframe
pourpoint <- data.frame("easting" = c(zz_coords[1]),
                        "northing" = c(zz_coords[2]))
#provide crs for shapefile and rasters
utm19nCRS <- CRS("+init=epsg:4326")
#convert dataframe to shapefile
r <- SpatialPointsDataFrame(pourpoint[,1:2], pourpoint[,1:2], proj4string = utm19nCRS)
#save shapefile
raster::shapefile(r, "MyShapefile.shp", overwrite = TRUE)

#perform whitebox watershed function over 5m resolution d8 pointer, using pour point
wbt_watershed(
  d8_pntr = d8,
  pour_pts = "MyShapefile.shp",
  output = "test.tif"
)

test <- raster("test.tif")
plot(test)
#find the sum of values in the raster
#first test if the raster is too big to look through in the memory
canProcessInMemory(test)
#size of W3 in ha- 42.1925 ha
#fb = 30.65
#zz = 25.25

sum(values(test), na.rm=TRUE) *25 /10000


#wbt_fill_single_cell_pits(
#                    dem = "McDonaldHollowDEM/brushDEMsm_5m_crs.tif",
 #                   output = "McDonaldHollowDEM/bmstationdem_filled.tif")

breach_output <- "./w3_dems/w3_dem_breached.tif"
wbt_breach_depressions_least_cost(
  dem = dem,
  output = breach_output,
  dist = 5,
  fill = TRUE)

fill_output <- "./w3_dems/w3_dem_filled.tif"
wbt_fill_depressions_wang_and_liu(
  dem = breach_output,
  output = fill_output
)

flowacc_output <- "./w3_dems/w3_dem_flowacc.tif"
wbt_d_inf_flow_accumulation(input = fill_output,
                            output = flowacc_output,
                            out_type = "Specific Contributing Area")

slope_output <- "./w3_dems/w3_dem_slope.tif"
wbt_slope(dem = fill_output,
          output = slope_output,
          units = "degrees")

twi_output <- "./w3_dems/w3_dem_twi.tif"
wbt_wetness_index(sca = flowacc_output, #flow accumulation
                  slope = slope_output,
                  output = twi_output)
# create pour points
WGScoor<-  MyData
> coordinates(WGScoor)=~long+lat
> proj4string(WGScoor)<- CRS("+proj=longlat +datum=WGS84")



twi <- raster(twi_output)
dem <- raster(dem)
plot(twi)

```